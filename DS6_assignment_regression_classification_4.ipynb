{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IXUfiQ2UKj6"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Regression & Classification, Module 4\n",
    "\n",
    "## Assignment\n",
    "\n",
    "- [X] Watch Aaron Gallant's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
    "- [X] Do train/validate/test split with the Tanzania Waterpumps data.\n",
    "- [X] Do one-hot encoding. (Remember it may not work with high cardinality categoricals.)\n",
    "- [X] Use scikit-learn for logistic regression.\n",
    "- [X] Get your validation accuracy score.\n",
    "- [X] Get and plot your coefficients.\n",
    "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "> [Do Not Copy-Paste.](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit) You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons.\n",
    "\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "### Doing\n",
    "- [ ] Add your own stretch goal(s) !\n",
    "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
    "- [ ] Make exploratory visualizations.\n",
    "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
    "\n",
    "\n",
    "#### Exploratory visualizations\n",
    "\n",
    "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
    "\n",
    "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
    "\n",
    "```python\n",
    "train['functional'] = (train['status_group']=='functional').astype(int)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
    "\n",
    "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
    "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
    "\n",
    "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this problem, you may want to use the parameter `logistic=True`\n",
    "\n",
    "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
    "\n",
    "#### High-cardinality categoricals\n",
    "\n",
    "This code from the previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
    "\n",
    "```python\n",
    "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
    "\n",
    "# Get a list of the top 10 neighborhoods\n",
    "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
    "\n",
    "# At locations where the neighborhood is NOT in the top 10,\n",
    "# replace the neighborhood with 'OTHER'\n",
    "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
    "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
    "```\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "[Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/compose.html) explains why pipelines are useful, and demonstrates how to use them:\n",
    "\n",
    "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
    "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
    "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "### Reading\n",
    "- [ ] [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
    "- [ ] [Always start with a stupid model, no exceptions](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)\n",
    "- [ ] [Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
    "- [ ] [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9eSnDYhUGD7"
   },
   "outputs": [],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    # Install required python packages:\n",
    "    # category_encoders, version >= 2.0\n",
    "    # pandas-profiling, version >= 2.0\n",
    "    # plotly, version >= 4.0\n",
    "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipBYS77PUwNR"
   },
   "outputs": [],
   "source": [
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJBD4ruICm1m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "assert train_features.shape == (59400, 40)\n",
    "assert train_labels.shape == (59400, 2)\n",
    "assert test_features.shape == (14358, 40)\n",
    "assert sample_submission.shape == (14358, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make like bananas and split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Amxyx3xphbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 40), (11880, 40), (47520,), (11880,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, train_size=0.80, test_size=0.20,\n",
    "    stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's One Hot Encoding! (And one good scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recorded_by</th>\n",
       "      <td>47520</td>\n",
       "      <td>1</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>47520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public_meeting</th>\n",
       "      <td>44876</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>40838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permit</th>\n",
       "      <td>45077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>31071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_class</th>\n",
       "      <td>47520</td>\n",
       "      <td>3</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>36638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management_group</th>\n",
       "      <td>47520</td>\n",
       "      <td>5</td>\n",
       "      <td>user-group</td>\n",
       "      <td>42027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity_group</th>\n",
       "      <td>47520</td>\n",
       "      <td>5</td>\n",
       "      <td>enough</td>\n",
       "      <td>26567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>47520</td>\n",
       "      <td>5</td>\n",
       "      <td>enough</td>\n",
       "      <td>26567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <td>47520</td>\n",
       "      <td>6</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>27642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_group</th>\n",
       "      <td>47520</td>\n",
       "      <td>6</td>\n",
       "      <td>good</td>\n",
       "      <td>40598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>47520</td>\n",
       "      <td>7</td>\n",
       "      <td>never pay</td>\n",
       "      <td>20287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_type</th>\n",
       "      <td>47520</td>\n",
       "      <td>7</td>\n",
       "      <td>spring</td>\n",
       "      <td>13620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterpoint_type</th>\n",
       "      <td>47520</td>\n",
       "      <td>7</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>22778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_class</th>\n",
       "      <td>47520</td>\n",
       "      <td>7</td>\n",
       "      <td>gravity</td>\n",
       "      <td>21448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment</th>\n",
       "      <td>47520</td>\n",
       "      <td>7</td>\n",
       "      <td>never pay</td>\n",
       "      <td>20287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water_quality</th>\n",
       "      <td>47520</td>\n",
       "      <td>8</td>\n",
       "      <td>soft</td>\n",
       "      <td>40598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basin</th>\n",
       "      <td>47520</td>\n",
       "      <td>9</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>8137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>47520</td>\n",
       "      <td>10</td>\n",
       "      <td>spring</td>\n",
       "      <td>13620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheme_management</th>\n",
       "      <td>44392</td>\n",
       "      <td>12</td>\n",
       "      <td>VWC</td>\n",
       "      <td>29470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>47520</td>\n",
       "      <td>12</td>\n",
       "      <td>vwc</td>\n",
       "      <td>32449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type_group</th>\n",
       "      <td>47520</td>\n",
       "      <td>13</td>\n",
       "      <td>gravity</td>\n",
       "      <td>21448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraction_type</th>\n",
       "      <td>47520</td>\n",
       "      <td>18</td>\n",
       "      <td>gravity</td>\n",
       "      <td>21448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>47520</td>\n",
       "      <td>21</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>4250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lga</th>\n",
       "      <td>47520</td>\n",
       "      <td>124</td>\n",
       "      <td>Njombe</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_recorded</th>\n",
       "      <td>47520</td>\n",
       "      <td>349</td>\n",
       "      <td>2011-03-17</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funder</th>\n",
       "      <td>44616</td>\n",
       "      <td>1716</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>7321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installer</th>\n",
       "      <td>44603</td>\n",
       "      <td>1929</td>\n",
       "      <td>DWE</td>\n",
       "      <td>13978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ward</th>\n",
       "      <td>47520</td>\n",
       "      <td>2082</td>\n",
       "      <td>Igosi</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheme_name</th>\n",
       "      <td>24988</td>\n",
       "      <td>2563</td>\n",
       "      <td>K</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subvillage</th>\n",
       "      <td>47234</td>\n",
       "      <td>17231</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wpt_name</th>\n",
       "      <td>47520</td>\n",
       "      <td>30661</td>\n",
       "      <td>none</td>\n",
       "      <td>2879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count unique                      top   freq\n",
       "recorded_by            47520      1  GeoData Consultants Ltd  47520\n",
       "public_meeting         44876      2                     True  40838\n",
       "permit                 45077      2                     True  31071\n",
       "source_class           47520      3              groundwater  36638\n",
       "management_group       47520      5               user-group  42027\n",
       "quantity_group         47520      5                   enough  26567\n",
       "quantity               47520      5                   enough  26567\n",
       "waterpoint_type_group  47520      6       communal standpipe  27642\n",
       "quality_group          47520      6                     good  40598\n",
       "payment_type           47520      7                never pay  20287\n",
       "source_type            47520      7                   spring  13620\n",
       "waterpoint_type        47520      7       communal standpipe  22778\n",
       "extraction_type_class  47520      7                  gravity  21448\n",
       "payment                47520      7                never pay  20287\n",
       "water_quality          47520      8                     soft  40598\n",
       "basin                  47520      9            Lake Victoria   8137\n",
       "source                 47520     10                   spring  13620\n",
       "scheme_management      44392     12                      VWC  29470\n",
       "management             47520     12                      vwc  32449\n",
       "extraction_type_group  47520     13                  gravity  21448\n",
       "extraction_type        47520     18                  gravity  21448\n",
       "region                 47520     21                   Iringa   4250\n",
       "lga                    47520    124                   Njombe   2003\n",
       "date_recorded          47520    349               2011-03-17    474\n",
       "funder                 44616   1716   Government Of Tanzania   7321\n",
       "installer              44603   1929                      DWE  13978\n",
       "ward                   47520   2082                    Igosi    257\n",
       "scheme_name            24988   2563                        K    548\n",
       "subvillage             47234  17231                  Shuleni    420\n",
       "wpt_name               47520  30661                     none   2879"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below region won't OHE well\n",
    "X_train.describe(exclude='number').T.sort_values(by='unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fresh imports\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Select the features you want\n",
    "categorical_features = ['quantity']\n",
    "numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
    "features = categorical_features + numeric_features\n",
    "\n",
    "# Make a subset of train and test \n",
    "# that contains select features\n",
    "X_train_subset = X_train[features]\n",
    "X_val_subset = X_val[features]\n",
    "\n",
    "# It's like coding but in english\n",
    "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "X_train_encoded = encoder.fit_transform(X_train_subset)\n",
    "X_val_encoded = encoder.transform(X_val_subset)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train_encoded)\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=10000, n_jobs = -1)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How accurate was I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6579124579124579"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's about as accurate as Ryan2 predicted\n",
    "# I guess he was 100% accurate\n",
    "model.score(X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to graph those coefficients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "coefficients.sort_values().plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_subset = test_features[features]\n",
    "X_test_encoded = encoder.transform(X_test_subset)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred\n",
    "submission.to_csv('Sam-Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,status_group\n",
      "50785,functional\n",
      "51630,functional\n",
      "17168,functional\n",
      "45559,non functional\n",
      "49871,functional\n",
      "52449,functional\n",
      "24806,functional\n",
      "28965,non functional\n",
      "36301,non functional\n"
     ]
    }
   ],
   "source": [
    "%alias head powershell -command \"& {Get-Content %s -Head 10}\"\n",
    "%head Sam-Submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to use the Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\samue\\anaconda3\\lib\\site-packages (1.5.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (3.0.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (2019.6.16)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samue\\anaconda3\\lib\\site-packages (from kaggle) (4.32.1)\n",
      "Requirement already satisfied: text-unidecode==1.2 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\samue\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_regression_classification_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
