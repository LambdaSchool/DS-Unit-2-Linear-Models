{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_regression_classification_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauney/DS-Unit-2-Regression-Classification/blob/master/module4/assignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 4\n",
        "\n",
        "## Assignment\n",
        "\n",
        "- [X] Watch Aaron Gallant's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "- [X] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [X] Do one-hot encoding. (Remember it may not work with high cardinality categoricals.)\n",
        "- [X] Use scikit-learn for logistic regression.\n",
        "- [X] Get your validation accuracy score.\n",
        "- [X] Get and plot your coefficients.\n",
        "- [X] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [X] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "> [Do Not Copy-Paste.](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit) You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
        "- [X] Make exploratory visualizations.\n",
        "- [X] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
        "\n",
        "\n",
        "#### Exploratory visualizations\n",
        "\n",
        "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
        "\n",
        "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
        "\n",
        "```python\n",
        "train['functional'] = (train['status_group']=='functional').astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this problem, you may want to use the parameter `logistic=True`\n",
        "\n",
        "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
        "\n",
        "#### High-cardinality categoricals\n",
        "\n",
        "This code from the previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
        "\n",
        "```python\n",
        "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10,\n",
        "# replace the neighborhood with 'OTHER'\n",
        "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "```\n",
        "\n",
        "#### Pipelines\n",
        "\n",
        "[Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/compose.html) explains why pipelines are useful, and demonstrates how to use them:\n",
        "\n",
        "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
        "\n",
        "### Reading\n",
        "- [ ] [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
        "- [ ] [Always start with a stupid model, no exceptions](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)\n",
        "- [ ] [Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
        "- [ ] [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YOwbBxYaWp4",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBYS77PUwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAsb-evbT5xH",
        "colab_type": "text"
      },
      "source": [
        "## Profile the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xroZu5fYF9I",
        "colab_type": "text"
      },
      "source": [
        "### Features\n",
        "\n",
        "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:\n",
        "\n",
        "- `amount_tsh` : Total static head (amount water available to waterpoint)\n",
        "- `date_recorded` : The date the row was entered\n",
        "- `funder` : Who funded the well\n",
        "- `gps_height` : Altitude of the well\n",
        "- `installer` : Organization that installed the well\n",
        "- `longitude` : GPS coordinate\n",
        "- `latitude` : GPS coordinate\n",
        "- `wpt_name` : Name of the waterpoint if there is one\n",
        "- `num_private` :  \n",
        "- `basin` : Geographic water basin\n",
        "- `subvillage` : Geographic location\n",
        "- `region` : Geographic location\n",
        "- `region_code` : Geographic location (coded)\n",
        "- `district_code` : Geographic location (coded)\n",
        "- `lga` : Geographic location\n",
        "- `ward` : Geographic location\n",
        "- `population` : Population around the well\n",
        "- `public_meeting` : True/False\n",
        "- `recorded_by` : Group entering this row of data\n",
        "- `scheme_management` : Who operates the waterpoint\n",
        "- `scheme_name` : Who operates the waterpoint\n",
        "- `permit` : If the waterpoint is permitted\n",
        "- `construction_year` : Year the waterpoint was constructed\n",
        "- `extraction_type` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_group` : The kind of extraction the waterpoint uses\n",
        "- `extraction_type_class` : The kind of extraction the waterpoint uses\n",
        "- `management` : How the waterpoint is managed\n",
        "- `management_group` : How the waterpoint is managed\n",
        "- `payment` : What the water costs\n",
        "- `payment_type` : What the water costs\n",
        "- `water_quality` : The quality of the water\n",
        "- `quality_group` : The quality of the water\n",
        "- `quantity` : The quantity of water\n",
        "- `quantity_group` : The quantity of water\n",
        "- `source` : The source of the water\n",
        "- `source_type` : The source of the water\n",
        "- `source_class` : The source of the water\n",
        "- `waterpoint_type` : The kind of waterpoint\n",
        "- `waterpoint_type_group` : The kind of waterpoint\n",
        "\n",
        "### Labels\n",
        "\n",
        "There are three possible values:\n",
        "\n",
        "- `functional` : the waterpoint is operational and there are no repairs needed\n",
        "- `functional needs repair` : the waterpoint is operational, but needs repairs\n",
        "- `non functional` : the waterpoint is not operational"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Amxyx3xphbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_profiling\n",
        "train_features.profile_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7_ccSL9Xk7U",
        "colab_type": "text"
      },
      "source": [
        "## Begin with baselines for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKDi2KeRX24H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine majority class\n",
        "y_train = train_labels['status_group']\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exz3oXyUZLFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guess the majority class for every prediction\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)\n",
        "len(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9S0EJovZskT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy of majority class baseline = frequency of majority class\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UIPe46maCY6",
        "colab_type": "text"
      },
      "source": [
        "## Do train|validate|test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VslAKWc5aAb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = train_features\n",
        "y_train = train_labels['status_group']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, train_size=0.80, test_size=0.20,\n",
        "    stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-J0X0Ygbn5H",
        "colab_type": "text"
      },
      "source": [
        "## Use scikit-learn for logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv-hrBYrb702",
        "colab_type": "text"
      },
      "source": [
        "### Begin with baselines: fast, first models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmeIQQVubeu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop non-numeric features\n",
        "X_train_numeric = X_train.select_dtypes('number')\n",
        "X_val_numeric = X_val.select_dtypes('number')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgKHyXhecac2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for nulls and drop before fitting\n",
        "X_train_numeric.isnull().sum(), X_val_numeric.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwdrCZHncxoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_numeric, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOF5gHMdQQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate on validation data\n",
        "y_pred = model.predict(X_val_numeric)\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-vJJGDTdj-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as above in one lin\n",
        "model.score(X_val_numeric, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfwUOXw6dv9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What predictions does a logistic regression return?\n",
        "print(y_pred)\n",
        "pd.Series(y_pred).value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrNKQ8HEeTxw",
        "colab_type": "text"
      },
      "source": [
        "### Do one-hot encoding of categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdCil9OReZZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check \"cardinality\" of categorical features\n",
        "\n",
        "X_train.describe(exclude='number').T.sort_values(by='unique').head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGvtCDWFfdCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore 'quantity' feature\n",
        "X_train['quantity'].value_counts(dropna=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcTP0olAfs4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recombine X_train and y_train for exploratory data analysis\n",
        "train = X_train.copy()\n",
        "train['status_group'] = y_train\n",
        "\n",
        "# Now do groupby\n",
        "\n",
        "train.groupby('quantity')['status_group'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjLigLgbuAd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train['functional'] = train['status_group'] == 'functional'\n",
        "sns.catplot(x='quantity', y='functional', data=train, kind='bar');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkeRTaJeu1Zw",
        "colab_type": "text"
      },
      "source": [
        "### Do one-hot encoding and scale features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF3Spnbouknm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "categorical_features = ['quantity']\n",
        "numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "X_train_subset = X_train[features]\n",
        "X_val_subset = X_val[features]\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train_subset)\n",
        "X_val_encoded = encoder.transform(X_val_subset)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_val_scaled = scaler.transform(X_val_encoded)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy:', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzfIV0LT5Ykd",
        "colab_type": "text"
      },
      "source": [
        "### Get and plot coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB9sliZt5DP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, status in enumerate(model.classes_):\n",
        "  coefficients = pd.Series(model.coef_[i], X_train_encoded.columns)\n",
        "\n",
        "  coefficients.sort_values().plot.barh()\n",
        "  plt.title(status)\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-WxYUEeA_YA",
        "colab_type": "text"
      },
      "source": [
        "### Submit to predictive modeling competition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC1tHRgl5WH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put test_features through the same paces as train and validate\n",
        "X_test_subset = test_features[features]\n",
        "X_test_encoded = encoder.transform(X_test_subset)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "assert all(X_test_encoded.columns == X_train_encoded.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ8fyEPLBu9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('submission-01.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJVxsyF7CKq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head submission-01.csv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}