{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IXUfiQ2UKj6"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Regression & Classification, Module 4\n",
    "\n",
    "## Assignment\n",
    "\n",
    "- [ ] Watch Aaron Gallant's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
    "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
    "- [ ] Do one-hot encoding. (Remember it may not work with high cardinality categoricals.)\n",
    "- [ ] Use scikit-learn for logistic regression.\n",
    "- [ ] Get your validation accuracy score.\n",
    "- [ ] Get and plot your coefficients.\n",
    "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "> [Do Not Copy-Paste.](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit) You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons.\n",
    "\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "### Doing\n",
    "- [ ] Add your own stretch goal(s) !\n",
    "- [ ] Clean the data. For ideas, refer to [The Quartz guide to bad data](https://github.com/Quartz/bad-data-guide),  a \"reference to problems seen in real-world data along with suggestions on how to resolve them.\" One of the issues is [\"Zeros replace missing values.\"](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values)\n",
    "- [ ] Make exploratory visualizations.\n",
    "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html).\n",
    "\n",
    "\n",
    "#### Exploratory visualizations\n",
    "\n",
    "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
    "\n",
    "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
    "\n",
    "```python\n",
    "train['functional'] = (train['status_group']=='functional').astype(int)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
    "\n",
    "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
    "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
    "\n",
    "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this problem, you may want to use the parameter `logistic=True`\n",
    "\n",
    "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
    "\n",
    "#### High-cardinality categoricals\n",
    "\n",
    "This code from the previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
    "\n",
    "```python\n",
    "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
    "\n",
    "# Get a list of the top 10 neighborhoods\n",
    "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
    "\n",
    "# At locations where the neighborhood is NOT in the top 10,\n",
    "# replace the neighborhood with 'OTHER'\n",
    "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
    "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
    "```\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "[Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/compose.html) explains why pipelines are useful, and demonstrates how to use them:\n",
    "\n",
    "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
    "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
    "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "### Reading\n",
    "- [ ] [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
    "- [ ] [Always start with a stupid model, no exceptions](https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa)\n",
    "- [ ] [Statistical Modeling: The Two Cultures](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
    "- [ ] [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9eSnDYhUGD7"
   },
   "outputs": [],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    # Install required python packages:\n",
    "    # category_encoders, version >= 2.0\n",
    "    # pandas-profiling, version >= 2.0\n",
    "    # plotly, version >= 4.0\n",
    "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipBYS77PUwNR"
   },
   "outputs": [],
   "source": [
    "# Ignore this Numpy warning when using Plotly Express:\n",
    "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJBD4ruICm1m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
    "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
    "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
    "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
    "\n",
    "assert train_features.shape == (59400, 40)\n",
    "assert train_labels.shape == (59400, 2)\n",
    "assert test_features.shape == (14358, 40)\n",
    "assert sample_submission.shape == (14358, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import block\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "import category_encoders as ce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "amount_tsh               float64\n",
       "date_recorded             object\n",
       "funder                    object\n",
       "gps_height                 int64\n",
       "installer                 object\n",
       "longitude                float64\n",
       "latitude                 float64\n",
       "wpt_name                  object\n",
       "num_private                int64\n",
       "basin                     object\n",
       "subvillage                object\n",
       "region                    object\n",
       "region_code                int64\n",
       "district_code              int64\n",
       "lga                       object\n",
       "ward                      object\n",
       "population                 int64\n",
       "public_meeting            object\n",
       "recorded_by               object\n",
       "scheme_management         object\n",
       "scheme_name               object\n",
       "permit                    object\n",
       "construction_year          int64\n",
       "extraction_type           object\n",
       "extraction_type_group     object\n",
       "extraction_type_class     object\n",
       "management                object\n",
       "management_group          object\n",
       "payment                   object\n",
       "payment_type              object\n",
       "water_quality             object\n",
       "quality_group             object\n",
       "quantity                  object\n",
       "quantity_group            object\n",
       "source                    object\n",
       "source_type               object\n",
       "source_class              object\n",
       "waterpoint_type           object\n",
       "waterpoint_type_group     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing date feature to datetime format\n",
    "train_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Amxyx3xphbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 40), (11880, 40), (47520,), (11880,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-validation split\n",
    "\n",
    "X_train = train_features.copy()\n",
    "y_train = train_labels['status_group'].copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
    "    stratify = y_train, random_state = 42\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_recorded\n",
      "funder\n",
      "installer\n",
      "wpt_name\n",
      "basin\n",
      "subvillage\n",
      "region\n",
      "lga\n",
      "ward\n",
      "public_meeting\n",
      "recorded_by\n",
      "scheme_management\n",
      "scheme_name\n",
      "permit\n",
      "extraction_type\n",
      "extraction_type_group\n",
      "extraction_type_class\n",
      "management\n",
      "management_group\n",
      "payment\n",
      "payment_type\n",
      "water_quality\n",
      "quality_group\n",
      "quantity\n",
      "quantity_group\n",
      "source\n",
      "source_type\n",
      "source_class\n",
      "waterpoint_type\n",
      "waterpoint_type_group\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.select_dtypes('object').columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "amount_tsh               0\n",
       "date_recorded            0\n",
       "funder                   0\n",
       "gps_height               0\n",
       "installer                0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "wpt_name                 0\n",
       "num_private              0\n",
       "basin                    0\n",
       "subvillage               0\n",
       "region                   0\n",
       "region_code              0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "recorded_by              0\n",
       "scheme_management        0\n",
       "scheme_name              0\n",
       "permit                   0\n",
       "construction_year        0\n",
       "extraction_type          0\n",
       "extraction_type_group    0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "management_group         0\n",
       "payment                  0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quality_group            0\n",
       "quantity                 0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "source_type              0\n",
       "source_class             0\n",
       "waterpoint_type          0\n",
       "waterpoint_type_group    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the frame with the mode for object feature\n",
    "for column in X_train.select_dtypes('object').columns:\n",
    "    X_train[column].fillna(X_train[column].mode()[0], inplace=True)\n",
    "    X_val[column].fillna(X_train[column].mode()[0], inplace=True)\n",
    "    test_features[column].fillna(X_train[column].mode()[0], inplace=True)\n",
    "    \n",
    "# Fill the frame with the mean for numeric features\n",
    "for column in X_train.select_dtypes('number').columns:\n",
    "    X_train[column].fillna(X_train[column].mean(), inplace=True)\n",
    "    X_val[column].fillna(X_train[column].mean(), inplace=True)\n",
    "    test_features[column].fillna(X_train[column].mean(), inplace=True)\n",
    "    \n",
    "X_val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature - pump age\n",
    "X_train['pump_age'] = 2013 - X_train['construction_year']\n",
    "X_val['pump_age'] = 2013 - X_val['construction_year']\n",
    "test_features['pump_age'] = 2013 - test_features['construction_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -4.059696\n",
       "1    -3.309214\n",
       "2    -5.004344\n",
       "3    -9.418672\n",
       "4   -10.950412\n",
       "Name: latitude, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features['latitude'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature - Distance from Dodoma\n",
    "X_train['dodomadistance'] = (((X_train['latitude']-(6.1630))**2)+((X_train['longitude']-(35.7516))**2))**0.5\n",
    "X_val['dodomadistance'] = (((X_val['latitude']-(6.1630))**2)+((X_val['longitude']-(35.7516))**2))**0.5\n",
    "test_features['dodomadistance'] = (((test_features['latitude']-(6.1630))**2)+((test_features['longitude']-(35.7516))**2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.278912219173826"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.dodomadistance.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the ys to integers for the encoder\n",
    "mapdict = {\n",
    "    'functional': 1,\n",
    "    'non functional': -1,\n",
    "    'functional needs repair': 0\n",
    "}\n",
    "y_train = y_train.map(mapdict)\n",
    "y_val = y_val.map(mapdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\conno\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7553030303030303\n"
     ]
    }
   ],
   "source": [
    "# Using category encoder to establish feature rank\n",
    "\n",
    "categoryfeatures = X_train.select_dtypes(include = 'object').columns\n",
    "\n",
    "encoder = ce.cat_boost.CatBoostEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "\n",
    "model = LogisticRegressionCV()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting best features\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k = 42)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "#X_test_selected = selector.transform(X_test)\n",
    "\n",
    "X_train_selected.shape#, #X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "amount_tsh\n",
      "date_recorded\n",
      "funder\n",
      "gps_height\n",
      "installer\n",
      "longitude\n",
      "latitude\n",
      "wpt_name\n",
      "num_private\n",
      "basin\n",
      "subvillage\n",
      "region\n",
      "region_code\n",
      "district_code\n",
      "lga\n",
      "ward\n",
      "population\n",
      "public_meeting\n",
      "recorded_by\n",
      "scheme_management\n",
      "scheme_name\n",
      "permit\n",
      "construction_year\n",
      "extraction_type\n",
      "extraction_type_group\n",
      "extraction_type_class\n",
      "management\n",
      "management_group\n",
      "payment\n",
      "payment_type\n",
      "water_quality\n",
      "quality_group\n",
      "quantity\n",
      "quantity_group\n",
      "source\n",
      "source_type\n",
      "source_class\n",
      "waterpoint_type\n",
      "waterpoint_type_group\n",
      "pump_age\n",
      "dodomadistance\n"
     ]
    }
   ],
   "source": [
    "# List selected features\n",
    "\n",
    "all_names = X_train.columns\n",
    "selected_mask = selector.get_support()\n",
    "selected_names = all_names[selected_mask]\n",
    "\n",
    "for name in selected_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\conno\\Anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7553030303030303\n"
     ]
    }
   ],
   "source": [
    "# Cat-boosted logistic with best features\n",
    "\n",
    "X_train_subset = X_train[selected_names]\n",
    "X_val_subset = X_val[selected_names]\n",
    "\n",
    "encoder2 = ce.cat_boost.CatBoostEncoder()\n",
    "X_train_encoded2 = encoder2.fit_transform(X_train_subset, y_train)\n",
    "X_val_encoded2 = encoder2.transform(X_val_subset)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train_encoded2)\n",
    "X_val_scaled2 = scaler2.transform(X_val_encoded2)\n",
    "\n",
    "model2 = LogisticRegressionCV()\n",
    "model2.fit(X_train_scaled2, y_train)\n",
    "print('Validation Accuracy', model2.score(X_val_scaled2, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the test data\n",
    "X_test_subset = test_features[selected_names]\n",
    "X_test_encoded = encoder2.transform(X_test_subset)\n",
    "X_test_scaled = scaler2.transform(X_test_encoded)\n",
    "assert all(X_test_encoded.columns == X_train_encoded2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "amount_tsh               0\n",
       "date_recorded            0\n",
       "funder                   0\n",
       "gps_height               0\n",
       "installer                0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "wpt_name                 0\n",
       "num_private              0\n",
       "basin                    0\n",
       "subvillage               0\n",
       "region                   0\n",
       "region_code              0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "recorded_by              0\n",
       "scheme_management        0\n",
       "scheme_name              0\n",
       "permit                   0\n",
       "construction_year        0\n",
       "extraction_type          0\n",
       "extraction_type_group    0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "management_group         0\n",
       "payment                  0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quality_group            0\n",
       "quantity                 0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "source_type              0\n",
       "source_class             0\n",
       "waterpoint_type          0\n",
       "waterpoint_type_group    0\n",
       "pump_age                 0\n",
       "dodomadistance           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_encoded.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test data\n",
    "y_test_pred = model2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmapping the prediction\n",
    "y_test_pred = pd.Series(y_test_pred)\n",
    "unmapdict = {value: key for key, value in mapdict.items()}\n",
    "y_test_pred = y_test_pred.map(unmapdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting submission\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_test_pred\n",
    "submission.to_csv('submission-02.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_regression_classification_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
