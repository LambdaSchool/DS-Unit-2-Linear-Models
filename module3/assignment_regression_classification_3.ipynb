{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_regression_classification_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owenburton/DS-Unit-2-Regression-Classification/blob/master/module3/assignment_regression_classification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 3\n",
        "\n",
        "## Assignment\n",
        "\n",
        "We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "Instead, predict property sales prices for **One Family Dwellings** (`BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'`). \n",
        "\n",
        "Use a subset of the data where the **sale price was more than \\\\$100 thousand and less than $2 million.** \n",
        "\n",
        "The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n",
        "\n",
        "- [x] Do train/test split. Use data from January â€”Â March 2019 to train. Use data from April 2019 to test.\n",
        "- [x] Do one-hot encoding of categorical features.\n",
        "- [x] Do feature selection with `SelectKBest`.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [x] Fit a ridge regression model with multiple features.\n",
        "- [x] Get mean absolute error for the test set.\n",
        "- [x] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Instead of `RidgeRegression`, try `LinearRegression`. Depending on how many features you select, your errors will probably blow up! ðŸ’¥\n",
        "- [ ] Instead of `RidgeRegression`, try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
        "- [ ] Learn more about feature selection:\n",
        "    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if youâ€™re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n",
        "- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ipBYS77PUwNR",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "\n",
        "# Read New York City property sales data\n",
        "df = pd.read_csv('../data/condos/NYC_Citywide_Rolling_Calendar_Sales.csv')\n",
        "\n",
        "# Change column names: replace spaces with underscores\n",
        "df.columns = [col.replace(' ', '_') for col in df]\n",
        "\n",
        "# SALE_PRICE was read as strings.\n",
        "# Remove symbols, convert to integer\n",
        "df['SALE_PRICE'] = (\n",
        "    df['SALE_PRICE']\n",
        "    .str.replace('$','')\n",
        "    .str.replace('-','')\n",
        "    .str.replace(',','')\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# BOROUGH is a numeric column, but arguably should be a categorical feature,\n",
        "# so convert it from a number to a string\n",
        "df['BOROUGH'] = df['BOROUGH'].astype(str)\n",
        "\n",
        "# Reduce cardinality for NEIGHBORHOOD feature\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = df['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10, \n",
        "# replace the neighborhood with 'OTHER'\n",
        "df.loc[~df['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "\n",
        "# Use a subset of the original that includes One Family Dwellings and where\n",
        "# the sale price was more than $100 thousand and less than $2 million.\n",
        "\n",
        "df = df[(df['BUILDING_CLASS_CATEGORY'] == '01 ONE FAMILY DWELLINGS') & \n",
        "        (df['SALE_PRICE'] > 100000) & (df['SALE_PRICE'] < 2000000)]\n",
        "\n",
        "# Drop NaNs.\n",
        "df = df.dropna(axis='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSW6e8458TVy",
        "colab_type": "text"
      },
      "source": [
        "##  Do train/test split. Use data from January â€” March 2019 to train. Use data from April 2019 to test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgb6uCI-4c2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do train/test split. \n",
        "# Use data from January â€” March 2019 to train. \n",
        "# Use data from April 2019 to test.\n",
        "\n",
        "df['SALE_DATE'] = pd.to_datetime(df['SALE_DATE'], infer_datetime_format=True)\n",
        "train = df[df['SALE_DATE'].dt.month < 4]\n",
        "test = df[df['SALE_DATE'].dt.month == 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOdqn1Bu8gbb",
        "colab_type": "text"
      },
      "source": [
        "## Do one-hot encoding of categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeS_grteJYB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop columns with high cardinality and high freq. of one observation.\n",
        "nopes = ['BUILDING_CLASS_CATEGORY', 'TAX_CLASS_AT_PRESENT',\n",
        "             'SALE_DATE', 'LAND_SQUARE_FEET', 'ADDRESS']\n",
        "train = train.drop(columns=nopes)\n",
        "test = test.drop(columns=nopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nykOepQGLUSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'SALE_PRICE'\n",
        "features = train.columns.drop([target])\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "279Ld9GzN41D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GETh3Jpp8iNH",
        "colab_type": "text"
      },
      "source": [
        "## Do feature selection with SelectKBest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2-3EOZ_8sa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "selector = SelectKBest(score_func=f_regression, k=15)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKkydefb8wOq",
        "colab_type": "text"
      },
      "source": [
        "## Do feature scaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_HuBYOM8xAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not required."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKMEMskq8xnQ",
        "colab_type": "text"
      },
      "source": [
        "## Fit a ridge regression model with multiple features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_TZP0dF82rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge_reg_split = Ridge().fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qijvJag887oV",
        "colab_type": "text"
      },
      "source": [
        " ## Get mean absolute error for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7WzFuTY8-Q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e177cb-b695-44b9-fdf2-4fc151eab445"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_test, ridge_reg_split.predict(X_test))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157960.691677068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUJguAZ1g-fP",
        "colab_type": "text"
      },
      "source": [
        "## Questions about the assignment.\n",
        "\n",
        "*   Why do we not instantiate Ridge like we do other models?\n",
        "*   Can you clarify what fit, transform, and fit_transform are doing exaclty? Like what's the process?\n",
        "\n"
      ]
    }
  ]
}