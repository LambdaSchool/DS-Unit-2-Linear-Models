{"cells":[{"cell_type":"markdown","metadata":{},"source":["Lambda School Data Science\n","\n","*Unit 2, Sprint 1, Module 3*\n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7IXUfiQ2UKj6"},"source":["# Ridge Regression\n","\n","## Assignment\n","\n","We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n","\n","But not just for condos in Tribeca...\n","\n","- [x] Use a subset of the data where `BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'` and the sale price was more than 100 thousand and less than 2 million.\n","- [x] Do train/test split. Use data from January â€”Â March 2019 to train. Use data from April 2019 to test.\n","- [x] Do one-hot encoding of categorical features.\n","- [ ] Do feature selection with `SelectKBest`.\n","- [ ] Fit a ridge regression model with multiple features. Use the `normalize=True` parameter (or do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html) beforehand â€”Â use the scaler's `fit_transform` method with the train set, and the scaler's `transform` method with the test set)\n","- [ ] Get mean absolute error for the test set.\n","- [ ] As always, commit your notebook to your fork of the GitHub repo.\n","\n","The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n","\n","\n","## Stretch Goals\n","\n","Don't worry, you aren't expected to do all these stretch goals! These are just ideas to consider and choose from.\n","\n","- [ ] Add your own stretch goal(s) !\n","- [ ] Instead of `Ridge`, try `LinearRegression`. Depending on how many features you select, your errors will probably blow up! ðŸ’¥\n","- [ ] Instead of `Ridge`, try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n","- [ ] Learn more about feature selection:\n","    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n","    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n","    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n","    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n","    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n","- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if youâ€™re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n","- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way.\n","- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["%%capture\n","import sys\n","\n","# If you're on Colab:\n","if 'google.colab' in sys.modules:\n","    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n","    !pip install category_encoders==2.*\n","\n","# If you're working locally:\n","else:\n","    DATA_PATH = '../data/'\n","\n","# Ignore this Numpy warning when using Plotly Express:\n","# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n","import warnings\n","warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# breaks local envviroment it's not being used so i went ahead and commented it out\n","#import pandas_profiling\n","\n","# Read New York City property sales data\n","df = pd.read_csv(DATA_PATH+'condos/NYC_Citywide_Rolling_Calendar_Sales.csv')\n","\n","# Change column names: replace spaces with underscores\n","df.columns = [col.replace(' ', '_') for col in df]\n","\n","# SALE_PRICE was read as strings.\n","# Remove symbols, convert to integer\n","df['SALE_PRICE'] = (\n","    df['SALE_PRICE']\n","    .str.replace('$','')\n","    .str.replace('-','')\n","    .str.replace(',','')\n","    .astype(int)\n",")"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["# BOROUGH is a numeric column, but arguably should be a categorical feature,\n","# so convert it from a number to a string\n","df['BOROUGH'] = df['BOROUGH'].astype(str)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["# Reduce cardinality for NEIGHBORHOOD feature\n","\n","# Get a list of the top 10 neighborhoods\n","top10 = df['NEIGHBORHOOD'].value_counts()[:10].index\n","\n","# At locations where the neighborhood is NOT in the top 10, \n","# replace the neighborhood with 'OTHER'\n","df.loc[~df['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["# make a copy of that data so that I don't mess anything up\n","copy=df.copy()\n","# make a mask for building class category\n","condition=copy['BUILDING_CLASS_CATEGORY']=='01 ONE FAMILY DWELLINGS'\n","copy=copy[condition]\n","# make a mask for building sales price\n","condition=(copy['SALE_PRICE']<2000000) | (copy['SALE_PRICE']>100000)\n","copy=copy[condition]"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["# make a new column to sort date\n","copy['dt']=pd.to_datetime(copy['SALE_DATE'],infer_datetime_format=True)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["# make train test split\n","train=copy[copy['dt'].dt.month<=3]\n","test=copy[copy['dt'].dt.month==4]\n"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"data":{"text/plain":"2019-01-01     9\n2019-01-02    39\n2019-01-03    63\n2019-01-04    61\n2019-01-05     8\n              ..\n2019-03-27    54\n2019-03-28    68\n2019-03-29    96\n2019-03-30     2\n2019-03-31     1\nName: dt, Length: 90, dtype: int64"},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["# check the train set to see if it includes what i want\n","train['dt'].value_counts().sort_index()"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"data":{"text/plain":"2019-04-15    62\n2019-04-05    58\n2019-04-10    56\n2019-04-01    55\n2019-04-12    55\n2019-04-04    54\n2019-04-11    54\n2019-04-02    54\n2019-04-09    51\n2019-04-18    50\n2019-04-08    50\n2019-04-03    47\n2019-04-17    43\n2019-04-16    43\n2019-04-30    32\n2019-04-25    31\n2019-04-23    31\n2019-04-22    31\n2019-04-29    28\n2019-04-19    28\n2019-04-24    25\n2019-04-26    16\n2019-04-14     4\n2019-04-13     3\n2019-04-07     2\n2019-04-28     1\n2019-04-06     1\n2019-04-27     1\n2019-04-20     1\nName: dt, dtype: int64"},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["# check the test set to see if it includes what i need\n","test['dt'].value_counts()"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BOROUGH</th>\n      <th>NEIGHBORHOOD</th>\n      <th>BUILDING_CLASS_CATEGORY</th>\n      <th>TAX_CLASS_AT_PRESENT</th>\n      <th>BUILDING_CLASS_AT_PRESENT</th>\n      <th>ADDRESS</th>\n      <th>APARTMENT_NUMBER</th>\n      <th>LAND_SQUARE_FEET</th>\n      <th>BUILDING_CLASS_AT_TIME_OF_SALE</th>\n      <th>SALE_DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>2</td>\n      <td>4094</td>\n      <td>4094</td>\n      <td>4094</td>\n    </tr>\n    <tr>\n      <td>unique</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15</td>\n      <td>4059</td>\n      <td>2</td>\n      <td>1280</td>\n      <td>12</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <td>top</td>\n      <td>4</td>\n      <td>OTHER</td>\n      <td>01 ONE FAMILY DWELLINGS</td>\n      <td>1</td>\n      <td>A1</td>\n      <td>1634 59TH STREET</td>\n      <td>8</td>\n      <td>4,000</td>\n      <td>A1</td>\n      <td>03/29/2019</td>\n    </tr>\n    <tr>\n      <td>freq</td>\n      <td>1993</td>\n      <td>3826</td>\n      <td>4094</td>\n      <td>4058</td>\n      <td>1542</td>\n      <td>3</td>\n      <td>1</td>\n      <td>412</td>\n      <td>1543</td>\n      <td>96</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       BOROUGH NEIGHBORHOOD  BUILDING_CLASS_CATEGORY TAX_CLASS_AT_PRESENT  \\\ncount     4094         4094                     4094                 4094   \nunique       5            9                        1                    3   \ntop          4        OTHER  01 ONE FAMILY DWELLINGS                    1   \nfreq      1993         3826                     4094                 4058   \n\n       BUILDING_CLASS_AT_PRESENT           ADDRESS APARTMENT_NUMBER  \\\ncount                       4094              4094                2   \nunique                        15              4059                2   \ntop                           A1  1634 59TH STREET                8   \nfreq                        1542                 3                1   \n\n       LAND_SQUARE_FEET BUILDING_CLASS_AT_TIME_OF_SALE   SALE_DATE  \ncount              4094                           4094        4094  \nunique             1280                             12          90  \ntop               4,000                             A1  03/29/2019  \nfreq                412                           1543          96  "},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["# take a look at diffrent categories that would be good to onehot encode\n","train.describe(include='object')"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"data":{"text/plain":"Index(['BOROUGH', 'NEIGHBORHOOD', 'TAX_CLASS_AT_PRESENT', 'BLOCK', 'LOT',\n       'EASE-MENT', 'ZIP_CODE', 'RESIDENTIAL_UNITS', 'COMMERCIAL_UNITS',\n       'TOTAL_UNITS', 'LAND_SQUARE_FEET', 'GROSS_SQUARE_FEET', 'YEAR_BUILT',\n       'TAX_CLASS_AT_TIME_OF_SALE'],\n      dtype='object')"},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["# set features based on the cardinality of the data in them\n","target='SALE_PRICE'\n","ignore=['dt','BUILDING_CLASS_CATEGORY','BUILDING_CLASS_AT_PRESENT','ADDRESS','APARTMENT_NUMBER','SALE_DATE','BUILDING_CLASS_AT_TIME_OF_SALE']\n","features=train.columns.drop([target]+ignore)\n","# print shape\n","features"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["# make cv split\n","X_train=train[features]\n","y_train=train[target]\n","X_test=test[features]\n","y_test=test[target]\n"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["# use one hot encoding to encode some of my catigorical variables\n","import category_encoders as ce\n","encode=ce.OneHotEncoder(use_cat_names=True)\n","X_train = encode.fit_transform(X_train)\n","X_test = encode.transform(X_test)\n"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found array with 0 sample(s) (shape=(0, 1307)) while a minimum of 1 is required.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-97-8b772d97ac26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# in the example for lecture it was about 1/2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train_selected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_test_selected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \"\"\"\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    548\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 550\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1307)) while a minimum of 1 is required."]}],"source":["# use selectKbest to select my best features, or features with highest explained variance\n","from sklearn.feature_selection import SelectKBest,f_regression\n","# note that im using 5 features her to reduce the dimentions of my feature matrix by a factor of 2/3\n","# in the example for lecture it was about 1/2\n","selector=SelectKBest(score_func=f_regression,k=5)\n","X_train_selected=selector.fit_transform(X_train,y_train)\n","X_test_selected=selector.transform(X_test,y_test)\n"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["X_test[\"y\"]=y_test\n","X_train[\"y\"]=y_train\n","X_test.dropna(inplace=True)\n","X_train.dropna(inplace=True)\n","y_test=X_test['y']\n","y_train=X_train['y']\n","X_test.drop('y',axis=1,inplace=True)\n","X_train.drop('y',axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6-final"}},"nbformat":4,"nbformat_minor":1}