{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn95EAVVPd0z"
   },
   "source": [
    "# Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 1, Module 2*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VNmSFcKjPd0_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKqnwgbKPd1D"
   },
   "source": [
    "# Module Project: Regression II\n",
    "\n",
    "In this project, you'll continue working with the New York City rent dataset you used in the last module project.\n",
    "\n",
    "## Directions\n",
    "\n",
    "The tasks for this project are as follows:\n",
    "\n",
    "- **Task 1:** Import `csv` file using `wrangle` function.\n",
    "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function to engineer two new features.\n",
    "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
    "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
    "- **Task 5:** Establish the baseline mean absolute error for your dataset.\n",
    "- **Task 6:** Build and train a `Linearregression` model.\n",
    "- **Task 7:** Calculate the training and test mean absolute error for your model.\n",
    "- **Task 8:** Calculate the training and test $R^2$ score for your model.\n",
    "- **Stretch Goal:** Determine the three most important features for your linear regression model.\n",
    "\n",
    "**Note**\n",
    "\n",
    "You should limit yourself to the following libraries for this project:\n",
    "\n",
    "- `matplotlib`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbLxF35NPd1F"
   },
   "source": [
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_1d1cMIXvkmk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zQaGIQc0Pd1G"
   },
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    #df = pd.read_csv(filepath)\n",
    "    #df = pd.read_csv(filepath, parse_dates=['created'], index_col='created')\n",
    "    #making an index 'created' as datetime, either order...\n",
    "    df = pd.read_csv(filepath, index_col = ['created'],parse_dates = ['created'])\n",
    "    # Remove the most extreme 1% prices,\n",
    "    # the most extreme .1% latitudes, &\n",
    "    # the most extreme .1% longitudes\n",
    "    df = df[(df['price'] >= np.percentile(df['price'], 0.5))\n",
    "            & (df['price'] <= np.percentile(df['price'], 99.5))\n",
    "            & (df['latitude'] >= np.percentile(df['latitude'], 0.05))\n",
    "            & (df['latitude'] < np.percentile(df['latitude'], 99.95))\n",
    "            & (df['longitude'] >= np.percentile(df['longitude'], 0.05))\n",
    "            & (df['longitude'] <= np.percentile(df['longitude'], 99.95))]\n",
    "            # BLOCKER: missed putting bracket wasting days, i need to break up code cells or find method to clean them. Read clean code book maybe.\n",
    "            # I added these because of an extreme 10 bathroom property to see how it affected results\n",
    "            # (df['bathrooms'] >= np.percentile(df['bathrooms'], 0.0)) & \n",
    "            # (df['bathrooms'] <= np.percentile(df['bathrooms'], 99.99))]\n",
    "    # Task 2: Conduct exploratory data analysis (EDA), and modify wrangle function to engineer two new features.\n",
    "    # BLOCKER: cant use dot method to create this feature.\n",
    "    # This feature asks if any places deny either cats but not dogs or vice versa.\n",
    "    df['petBias'] = (df['cats_allowed'] != df['dogs_allowed']).astype(int)\n",
    "    # Alternative format just to see what happens to neither True cases. Null, nan or what?\n",
    "    # df.loc[(df['dogs_allowed'] == 1) & (df['cats_allowed'] == 0), 'petBias'] = 1\n",
    "    # df.loc[(df['dogs_allowed'] != 1) & (df['cats_allowed'] != 0), 'petBias'] = 1\n",
    "\n",
    "    # This is supposed to say if neither true then 1(True). It seems to work somehow but have yet to verify.\n",
    "    df['inaccessible'] = abs((df['wheelchair_access']  + df['elevator'])-1).astype(int)\n",
    "\n",
    "    df.dropna(axis=0, inplace=True) # axis=0 specifies rows.\n",
    "\n",
    "    df['total_rooms'] = df[['bathrooms','bedrooms','dining_room']].sum(axis = 1) \n",
    "    # Specifying columns (axis=1) is maybe redundant?\n",
    "    # df['total_rooms'] =  df['bathrooms'] + df['bedrooms']+ df['dining_room']\n",
    "\n",
    "    df.drop(columns = df.select_dtypes('object').columns, inplace = True)\n",
    "    return df \n",
    "\n",
    "filepath = DATA_PATH + 'apartments/renthop-nyc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMyYR44cPd1I"
   },
   "source": [
    "**Task 1:** Add the following functionality to the above `wrangle` function.\n",
    "\n",
    "- The `'created'` column will parsed as a `DateTime` object and set as the `index` of the DataFrame. \n",
    "- Rows with `NaN` values will be dropped.\n",
    "\n",
    "Then use your modified function to import the `renthop-nyc.csv` file into a DataFrame named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtL8hElWPd1L",
    "outputId": "7e37c1d3-e194-4522-ca91-f01c918c4d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     37816\n",
       "2.0      7421\n",
       "3.0       663\n",
       "1.5       641\n",
       "0.0       304\n",
       "2.5       256\n",
       "4.0        91\n",
       "3.5        55\n",
       "4.5         8\n",
       "5.0         4\n",
       "10.0        1\n",
       "Name: bathrooms, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Task 1: Import csv file using wrangle function.\n",
    "# BLOCKER: generic \"name\" error without imports first\n",
    "df = wrangle(filepath)\n",
    "df['bathrooms'].value_counts(ascending=False,sort=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lijwyNHsPd1P"
   },
   "source": [
    "**Task 2:** Using your `pandas` and dataviz skills decide on two features that you want to engineer for your dataset. Next, modify your `wrangle` function to add those features. \n",
    "\n",
    "**Note:** You can learn more about feature engineering [here](https://en.wikipedia.org/wiki/Feature_engineering). Here are some ideas for new features:\n",
    "\n",
    "- Does the apartment have a description?\n",
    "- Length of description.\n",
    "- Total number of perks that apartment has.\n",
    "- Are cats _or_ dogs allowed?\n",
    "- Are cats _and_ dogs allowed?\n",
    "- Total number of rooms (beds + baths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "id": "DB-vlNf0Pd1S",
    "outputId": "077287bd-cf27-420a-e03a-a9b160cfb4ed"
   },
   "outputs": [],
   "source": [
    "# Conduct your exploratory data analysis here, \n",
    "# and then modify the function above.\n",
    "# Theory: predict price based on whether accessible.\n",
    "#plt.scatter(x='bedrooms', y='price', data=df)\n",
    "plt.scatter(x='bathrooms', y='price', data=df)\n",
    "#plt.scatter(x='inaccessible', y='price', data=df)\n",
    "#plt.scatter(x='Outdoor_perks', y='price', data=df)\n",
    "df.info()\n",
    "#sns.regplot(x='bedrooms', y='price', data=df, fit_reg=True)\n",
    "#df['wheelchair_access'].value_counts()\n",
    "#df['inaccessible'].sort_values(ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ueh0iBtjvW3a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDEuLhd7Pd1T"
   },
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'price'`.\n",
    "\n",
    "**Note:** In contrast to the last module project, this time you should include _all_ the numerical features in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPGawcn6Pd1U",
    "outputId": "8dc7433f-8608-4a5d-b925-0e050e3c2341"
   },
   "outputs": [],
   "source": [
    "target = 'price'\n",
    "\n",
    "#X = df.select_dtypes('number').drop(columns=target)\n",
    "# is the same as saying...\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "print(f'Feature matrix (X) shape: {X.shape}\\nTarget vector (y) shape: {y.shape}')\n",
    "# show target (price) is missing\n",
    "X.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywpeP8UaPd1V"
   },
   "source": [
    "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
    "\n",
    "- Your training set should include data from April and May 2016. \n",
    "- Your test set should include data from June 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "hqWNlFVwPd1W",
    "outputId": "45f01b57-ce83-4a47-f322-a7e699a144c5"
   },
   "outputs": [],
   "source": [
    "# X_train, y_train = ..., ...\n",
    "# X_test, y_test = ..., ...\n",
    "#df=df.sort_index()\n",
    "\n",
    "#X_train, y_train = X.loc['2016-04-01' : '2016-05-31'], y.loc['2016-04-01' : '2016-05-31']\n",
    "#X_test, y_test = X.loc['2016-06-01' : '2016-06-30'], y.loc['2016-06-01' : '2016-06-30']\n",
    "\n",
    "# Creating the cutoff for training and test data sets\n",
    "\n",
    "cutoff = '2016-06-01'\n",
    "mask = X.index < cutoff\n",
    "X_train, y_train = X.loc[mask], y.loc[mask]\n",
    "X_test, y_test = X.loc[~mask], y.loc[~mask]\n",
    "\n",
    "# can be shorter with...\n",
    "#cutoff = X.index <'2016-06-01'\n",
    "\n",
    "# Creating the training data set\n",
    "#X_train, y_train = X.loc[cutoff], y.loc[cutoff]\n",
    "\n",
    "# Creating the test data set\n",
    "#X_test, y_test = X.loc[~cutoff], y.loc[~cutoff]\n",
    "\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ6gUKD9Pd1X"
   },
   "source": [
    "# III. Establish Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5BuXPDXPd1Y"
   },
   "source": [
    "**Task 5:** Since this is a **regression** problem, you need to calculate the baseline mean absolute error for your model. First, calculate the mean of `y_train`. Next, create a list `y_pred` that has the same length as `y_train` and where every item in the list is the mean. Finally, use `mean_absolute_error` to calculate your baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn-60SiAPd1Y",
    "outputId": "a1fd6fed-b48c-4bb9-92a6-90b69be22373"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = [y_train.mean()] * len(y_train)\n",
    "baseline_mae = mean_absolute_error(y_train, y_pred) \n",
    "\n",
    "print('Baseline MAE:', baseline_mae)\n",
    "print('Mean Apartment rent', y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5WYK_ZGPd1Z"
   },
   "source": [
    "# IV. Build Model\n",
    "\n",
    "**Task 6:** Build and train a `LinearRegression` model named `model` using your feature matrix `X_train` and your target vector `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Gp7rIz0Pd1a",
    "outputId": "f4965d1e-b4c1-4b92-8d01-cc5fb211fc6e"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import predictor class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 2: Instantiate predictor\n",
    "model = LinearRegression()\n",
    "\n",
    "# Step 3: Fit predictor on the (training) data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhBepsBNPd1a"
   },
   "source": [
    "# V. Check Metrics\n",
    "\n",
    "**Task 7:** Calculate the training and test mean absolute error for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KH0TQtskPd1b",
    "outputId": "b80aa2d0-3bb3-4199-ad90-36b61a3fa5b5"
   },
   "outputs": [],
   "source": [
    "#In two steps...\n",
    "#y_pred_train = model.predict(X_train)\n",
    "#y_pred_test = model.predict(X_test)\n",
    "##NotFittedError: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
    "#training_mae = mean_absolute_error(y_pred_train,y_train)\n",
    "#test_mae = mean_absolute_error(y_pred_test,y_test)\n",
    "\n",
    "#In one...\n",
    "training_mae = mean_absolute_error(y_train, model.predict(X_train))\n",
    "test_mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "\n",
    "print('Training MAE:', training_mae)\n",
    "print('Test MAE:', test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3ArwXFMPd1c"
   },
   "source": [
    "**Task 8:** Calculate the training and test $R^2$ score for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBdt2XUQPd1e",
    "outputId": "5dbbaf61-5554-4c37-9ef8-0f297a123c7c"
   },
   "outputs": [],
   "source": [
    "training_r2 = model.score(X_train,y_train)\n",
    "test_r2 = model.score(X_test,y_test)\n",
    "\n",
    "print('Training MAE:', training_r2)\n",
    "print('Test MAE:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdgVaO94Pd1g"
   },
   "source": [
    "# VI. Communicate Results\n",
    "\n",
    "**Stretch Goal:** What are the three most influential coefficients in your linear model? You should consider the _absolute value_ of each coefficient, so that it doesn't matter if it's positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsHYFYMU5Cwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-uY9NjfIBGO",
    "outputId": "ec885ed5-a2e3-4414-dd9f-7aef59af16b6"
   },
   "outputs": [],
   "source": [
    "# Lets look at the coefficients and what they are associated with\n",
    "feature_importance = abs(pd.Series(model.coef_, index = X_train.columns)).sort_values()\n",
    "feature_importance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Xhu9GGvPd1h",
    "outputId": "5598f048-0564-42c3-b19f-96b7245fea9d"
   },
   "outputs": [],
   "source": [
    "feature_importance = abs(pd.Series(model.coef_, index = X_train.columns)).sort_values()\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "QJFn986_zdWq",
    "outputId": "74ec426a-8da2-4dad-917f-b4df4f023c69"
   },
   "outputs": [],
   "source": [
    "feature_importance.tail(10).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuA1R1Ooz97F",
    "outputId": "23156d78-4dd3-4f19-a51d-4f3f16059bf7"
   },
   "outputs": [],
   "source": [
    "feature_importance = abs(pd.Series(model.coef_, index=X_train.columns)).sort_values(key=abs).tail(10)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "bOVReOpMzprF",
    "outputId": "a1c7711a-0ea8-468e-c3cd-ec758f337462"
   },
   "outputs": [],
   "source": [
    "feature_importance = abs(pd.Series(model.coef_, index=X_train.columns)).sort_values(key=abs).tail(10)\n",
    "feature_importance.head()\n",
    "\n",
    "feature_importance.tail(10).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LS_DS_212_assignment.work.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
