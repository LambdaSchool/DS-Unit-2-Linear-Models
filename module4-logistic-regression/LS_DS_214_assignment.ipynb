{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Dan Anderson LS_DS_214_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jJS_eORU44H",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7LzE8diU44X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "755PbUz3U44h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bpZYx81U44n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB2c5_FSU44t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUuKhArkU44z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])\n",
        "df_sub = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScfJsgMjYUmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data in train, validate, and test datasets\n",
        "df_sub['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "cutoff_trn   = pd.to_datetime('2017-01-01')\n",
        "cutoff_val_a = pd.to_datetime('2016-12-31')\n",
        "cutoff_val_b = pd.to_datetime('2018-01-01')\n",
        "cutoff_tst_a = pd.to_datetime('2017-12-31')\n",
        "cutoff_tst_b = pd.datetime.today()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI8ZJVE2ZSjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate train, validate, and test dataframes by filtering on date\n",
        "df_train = df_sub[df_sub['Date'] < cutoff_trn]\n",
        "df_valdt = df_sub[((df_sub['Date'] > cutoff_val_a) & (df_sub['Date'] < cutoff_val_b))]\n",
        "df_test  = df_sub[((df_sub['Date'] > cutoff_tst_a) & (df_sub['Date'] < cutoff_tst_b))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54noaH9Icns1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct dependent and outcome datasets for the train, validate, and test dataframes\n",
        "df_train_X = df_train.drop(columns=['Great'])\n",
        "df_train_y = df_train['Great']\n",
        "\n",
        "df_valdt_X = df_valdt.drop(columns=['Great'])\n",
        "df_valdt_y = df_valdt['Great']\n",
        "\n",
        "df_test_X  = df_test.drop(columns=['Great'])\n",
        "df_test_y  = df_test['Great']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOSF3XwgQ0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3cac527-b8bd-44d0-cf42-78b60329754f"
      },
      "source": [
        "# Generate Baseline predictions\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# \"Fit\" the DummyClassifier model\n",
        "bselne = DummyClassifier(strategy='most_frequent')\n",
        "bselne.fit(df_train_X, df_train_y)\n",
        "\n",
        "# Calculate predictions using the validate dataset\n",
        "tmp_pred_y = bselne.predict(df_valdt_X)\n",
        "# Score the accuracy of the prediction\n",
        "acc_valdt = accuracy_score(df_valdt_y, tmp_pred_y)\n",
        "\n",
        "print(f'The Dummy Classifier model yields an accuracy of: {round(acc_valdt, 4)}')"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Dummy Classifier model yields an accuracy of: 0.5529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB86PPHM9thO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a set of simple, intuitive features that may predict the \"Great\" rating (more accurately than our baseline)\n",
        "features_intuitive = ['Burrito', 'Cost', 'Hunger', 'Temp', 'Meat', 'Fillings']\n",
        "target = ['Great']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O62swRf_QDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59812b14-1fda-4bcf-fa3d-616755d27ff7"
      },
      "source": [
        "# Prepare a logistic regression modeling approach\n",
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "train_X = df_train_X[features_intuitive]\n",
        "train_y = df_train_y\n",
        "\n",
        "val_X   = df_valdt_X[features_intuitive]\n",
        "val_y   = df_valdt_y\n",
        "\n",
        "test_x  = df_test_X[features_intuitive]\n",
        "test_y  = df_test_y\n",
        "print(train_X.shape, val_X.shape, test_x.shape)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298, 6) (85, 6) (37, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmmAuo-9F2IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "615625d8-b22d-4489-b392-73321814e401"
      },
      "source": [
        "# Encode categorical data as binary data columns\n",
        "encdr = ce.OneHotEncoder(use_cat_names=True)\n",
        "train_X_encded = encdr.fit_transform(train_X)\n",
        "val_X_encded   = encdr.transform(val_X)\n",
        "test_X_encded  = encdr.transform(test_x)\n",
        "print(train_X_encded.shape, val_X_encded.shape, test_X_encded.shape)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298, 10) (85, 10) (37, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbr6AINaG-zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Impute missing data values using the one hot encoded data as input\n",
        "imptr = SimpleImputer(strategy='mean')\n",
        "train_X_imptd = imptr.fit_transform(train_X_encded)\n",
        "val_X_imptd   = imptr.transform(val_X_encded)\n",
        "test_X_imptd  = imptr.transform(test_X_encded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6r0w-HdH7Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the feature data values in using a standard method feeding the imputed data as input\n",
        "sclr = StandardScaler()\n",
        "train_X_scaled = sclr.fit_transform(train_X_imptd)\n",
        "val_X_scaled   = sclr.transform(val_X_imptd)\n",
        "test_X_scaled  = sclr.transform(test_X_imptd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtHTVE4PImee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b4065dc-7d67-480b-a19e-0b7eebf22850"
      },
      "source": [
        "# Stand up a logistic modeling object\n",
        "mdl = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "# Fit the model using the scaled training independent variables and the training outcome value\n",
        "mdl.fit(train_X_scaled, train_y)\n",
        "\n",
        "# Calculate the accuracy using the validation data\n",
        "print(f'The Validation Accuracy is: {round(mdl.score(val_X_scaled, val_y), 4)}')"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Validation Accuracy is: 0.8824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk_Jo07hKaO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "016559ed-d20b-4664-848a-42a329a2629e"
      },
      "source": [
        "# Render the regression expression terms (coefficients, variables, and intercept)\n",
        "%matplotlib inline\n",
        "coefficients = pd.Series(mdl.coef_[0], train_X_encded.columns)\n",
        "coefficients.sort_values()\n",
        "\n",
        "tmp_series = pd.Series([mdl.intercept_[0]], ['(y intercept)'])\n",
        "coefficients = coefficients.append(tmp_series)\n",
        "coefficients.plot.barh();"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAD8CAYAAAABgWFAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5xcdX3/8VcIl3iJXGR/iBeIKL6R\n0loQIhcl4aKIYGsFimDrpdoLC7r9FYT82kJWUBvECFhEiiCRoq0CitwFpASBAEGQgpI3lppyEWW5\niEEpATK/P84ZMuzO7O4k2Z3Jmffz8eCRmTPf8z2f+e4kH77f79n5TKnVakRERFTVOp0OICIiYiIl\n0UVERKUl0UVERKUl0UVERKUl0UVERKUl0UVERKWt2+kAYqShoWU9/TsfG2/8Up544nedDqPrZFya\ny7iM1Ktj0tc3fUqz45nRRddZd92pnQ6hK2Vcmsu4jJQxebEkuoiIqLQkuoiIqLQkuoiIqLTcjFIx\nO82/vtMhxARZOm+/TocQsVbq2kQn6eXAxcABtp8Ypd0fAn9ie26L118B7Gz7qomJdMT1tgBeBdxD\nEf/7bD85GdeOiIiRunnpchD46mhJDsD2j1sludIOwLvWZGBj2BOYaXsZ8CXgs5N47YiIGKYrZ3SS\npgEHAsdIOgx4te1jy9euBo60/Z/l89nAEbYPlPRfwEXAbsCvgf2ALwOvkHQvcClwNrA+8Dzwcdv3\nS/oZcDtwVfnn6cAK4Cbbn5K0LXAaUAOWAR8BNgLOB+4F3gQsBuZSJOhnJd1fxnKipJfbfmqChisi\nIkbRrTO6mcB/2n4e+BbwPgBJGwKvrCe5JrYCzrW9C7Ax8AfAScC3bJ8JnADMt70XcApwbMN5x9s+\nm2IW9te2dwM2k7Ql8M/lsb0okuHh5XlvAeaU8e4EvBpYAJxq+2LbNeA2YJc1MCYREbEKunJGR5Ew\nHgSw/bikn0naARDFLKqV3zQkwQeBDYe9visgSf8ITAWGyuO/tf2T8rHqfdj+EMUJM4GvSgLYgGL2\nBnCv7QfKNreU8Q33IPC6sd6wpEGKGSH9/f0MDAyMdUr0oL6+6Z0OoStlXEbKmKzUrYkOimXCunOB\ng4Atgb8f5Zznhj0f/nUwy4GDbD/c5Hjdiib9/g7Yo5yhASBpBi+eEU8ZFnNbbA9SLHsyNLSsNjS0\nbFW7igrL52Kkvr7pGZdhenVMWiX3bl26/AXw2obnlwO7AxvZXtpmXytYmdBvYeUy6J6SDm3S/qeS\n3la2OVvSm4E7gXeXxz4gaa+y7RskbS5pHeBtwE+HXQ/gNZSz04iImHzdmuhuBd4iaSqA7eUUt+tf\nsgp93Q4cLOkoihnT+yRdT7FMuKhJ+wFgvqQbgCds31Me+3tJCyluRLmjbGvgc2U/N5XLn4uAoyV9\nUNIUir27m1Yh7oiIWAOm1Grd+UX5kr4I3GL7W+VdmD8E9u6W30krly4vsL3jKG3+GNjHdn87fa9O\n9YL8wnh1LZ23X08uR42lV5fpRtOrY9KqekE379HNBS4qb9M/AzipW5LceEiaDvwt8P7JvO7iI3ef\nzMtNiF79SxoRE6NrZ3S9rNfr0SXRNZdxaS7jMlKvjknq0UVERE9KoouIiEpLoouIiEpLoouIiEpL\noouIiEpLoouIiEpLoouIiEpLoouIiErr5m9GiYgGM+Zc1ukQItaoyfomp55LdOV3VN4F/Kjh8K+B\nO23PlfSo7U0lXQccAewIPGn7u5MebERErLaeS3Ql2549zoYLJjaUiIiYSL2a6F5E0mzgCNsHNnlt\nEHgUuJtihrcCeDNF5YJPS9obOAX4JUXZniHgZODbFNXINwAOt337xL+TiIgYLjejtGcmRT26XYBP\nlMdOBP4c2AfYvjy2F/BgOWv8IPB/JjXKiIh4Qa/O6FTuwdVdPc7zbrf9u7KD+rEtbd9RHrucYkwX\nAZ+RdAbwHdtXjiOgQYrSRPT39zMwMDDOkKqpr296p0OIiAk2WX/PezXRvWiPrly63L5l65WeG+P1\nWtn5w5LeAuwBHCZpZ9vHjxHQIEUFdIaGltV6scRGXa+WGInoNWv673mrxJmly9X3S0nbSJoKvAug\n3Lfb2/ZVFEucLauQR0TExOrVGd2a9I/Ad4CfA/cAzwP/BZwn6RiKm1fmdi68iIjelgrjq0nSu4B7\nbS+V9C/AQtvfXJ0+U2E8S5fNZFyay7iM1Ktj0qrCeGZ0q28K8F1Jy4BfARd0OJ6IiGiQRLeabH8f\n+H6n44iIiOZyM0pERFRaEl1ERFRaEl1ERFRaEl1ERFRaEl1ERFRaEl1ERFRaEl1ERFRafo8uYi0x\nY85lnQ4hYkItPnL3Cek3M7qIiKi0JLomJM2QVJO087DjiyUtaLOvP5D0pjUaYEREjFsSXWv/DRxS\nfyLpjcDGq9DP+4EkuoiIDskeXWs3A++UNNX288AHgKuAl0p6B/A54FngAeAvKcrxfB14LfAyiiKq\n/wP8DTAk6RHbt076u4iI6HFJdK09C9xCUSX8GuCPgU8DBwJfAvay/bikzwMHAVcDV9n+uqStgPNt\nv1XSlcAFYyU5SYOUdev6+/sZGBiYoLe1dmhVKTgiqmui/t4n0Y3ufOAQSb8EHgKeAjYDtga+IwmK\n2dujwBPATpL+imJ298p2LmR7kGIWyNDQslov1pKq69VaWhG9bnX/3rdKlEl0o7sGOA14mJV15pYD\nD9me3dhQ0oeBTYB3lH/eNnlhRkREK7kZZRS2lwPXAx8DLikPPwEgadvyz09I+gNgU+DntldQ3ICy\nftl+BfkfioiIjkmiG9v5wO22n2w49jHgHEk/BN4OGLgQeK+kHwC/BR6UdBzwQ+BLkvaa5LgjIgKY\nUqvVOh1DDDM0tKynfyjZo2su49JcxmWkXh2Tvr7pU5odz4wuIiIqLYkuIiIqLYkuIiIqLYkuIiIq\nLYkuIiIqLYkuIiIqLYkuIiIqLYkuIiIqLYkuIiIqLd/BGLGWmDHnsk6H0FUWH7l7p0OItUQSHSBp\nPvBW4FUUZXfuAx63/f6OBhYREastiQ6wfSSApI8A29k+qrMRRUTEmpJENwpJJwK7AFOBU21/W9J5\nwIPAThTFVb8AfISiBt0s4GBgT2Bj4DXAF2yfO/nRR0QE5GaUliTtAWxme3dgb2CupA3Kl5fb3oui\nPM9OtvcuH88qX98W2L8873OSmn6jdkRETLzM6FrbFdhN0nXl86kUe3gAt5Z/Pgz8uHz8K2DD8vF1\ntp8HHpH0FMXs7vHRLiZpEJgL0N/fz8DAwBp4C2uvvr7pnQ4hulzjZySfl5EyJisl0bW2HDjT9kmN\nByUBPNdwqPFxfea2zrBjY9aXsz0IDEJRj64Xa0nV9WotrWhP/TOSz8tIvTomrZJ7li5bu4WiYvg6\nkl4q6dQ2zt21PG8zYAPg1xMTYkREjCWJrgXb1wM3AYuA64Db2jj9fuBC4Brg/9nu6YrhERGdNKVW\ny7/Ba5KkjwNvtD1nVfsYGlrW0z+UXl12GctO86/vdAhdpf4L4/m8jNSrY9LXN73pjX/Zo4tYSyyd\nt19P/uMVsbqS6NYw22d1OoaIiFgpe3QREVFpSXQREVFpSXQREVFpSXQREVFpSXQREVFpSXQREVFp\nSXQREVFpSXQREVFp+YXxiLXEjDmXdeza9a/bilgb9dSMTtIMSbcNOzYo6YhOxRQREROrpxJdRET0\nnixdliTdZnvH+mPgQIpCqL8A3gpsAXzQ9u2SvkRRgfwngIAPUBRqPRtYH3ge+Ljt+yX9DLgduMr2\n2ZP7riIiohcTnSRd1/B8BvCFUdpvYHsfSX8DfEjSs8DbgR2B3wPuKNudAMy3fY2k9wDHAn8JbAW8\nz/ZP1uzbiIiI8ejFRGfbs+tPJA2O0f6H5Z8PAm8D3gzcbHsFcJekpeXruxbd6R+BqcBQefy340ly\nZRxzAfr7+xkYGBjHW6muvr7pnQ4hGnT7z6Pb4+uEjMlKvZjomnnlsOfrNTx+ruHxlPK/FQ3H6kVS\nlwMH2X54WF/LxxOA7UGKpVKGhpbVernuWK8Wjexm3fzzyOdlpF4dk1bJPYmusALYTNIUYDPgDaO0\nvQ/427LtNsCW5fFbgPcBX5G0J/Aq29+cwJgjImIckugKTwDXAIuBO1m57zaC7dsk3UuR2O4Afkpx\n88kgcI6kQyhmeR+Z2JAjImI8ptRqtbFbxQskbQAcbPtcSS8DlgCvt/3cGKeO29DQsp7+ofTqsstY\ndpp/fceu3c2/MJ7Py0i9OiZ9fdOnNDueGV2bbD8jaSdJn6RY8jx2TSa5iFaWztuvJ//xilhdSXSr\nwPYnOh1DRESMT74ZJSIiKi2JLiIiKi2JLiIiKi2JLiIiKi2JLiIiKi2JLiIiKi2JLiIiKi2JLiIi\nKi2/MB6xlpgx57JVOq+bv74rYjIk0Y1C0tbAKUAfRY25m4CjbD8zzvO3oKhicOvERRkREaPJ0mUL\nkqYCFwKftz2ToqI4wHFtdLMnMHNNxxYREeOXGV1r7wSW2F4IYLsm6WhghaQB4ANlu4tsnyjpXcBn\ngKeBXwGHU5TueVbS/bYvnvR3EBERmdGNYhvgx40HbD8NvJqi1tw7yv8OlvQG4AjgSNuzgH+nWOpc\nAJyaJBcR0TmZ0bVWo0hWw20P3FwvzSPpRuAtwPnAGZK+Afyb7V9KGvfFJA0CcwH6+/sZGBhYvejX\ncn190zsdQmX0wlj2wntsV8ZkpSS61pZQzNJeUBZd/T2gsbjf+sAK2/8q6fvA+4BLJB3YzsVsD1Is\ndTI0tKzWy3XHerVo5ESp+ljm8zJSr45Jq+SepcvWrga2lPReAEnrACcCbwJ2kbSupHWBtwF3SDoW\neNb2mRRLl9tSFGbN/0xERHRQEl0LtlcA+wB/Jek24AbgSeDDwJnAQuCHwFm2/we4H7hG0jUUS5lX\nAouAoyV9sANvISIiyGxjVLYfBt7b5KUvl/81tv068PVh7a6muHklIiI6JIkuYi2xdN5+PbnvErG6\nsnQZERGVlkQXERGVlkQXERGVlkQXERGVlkQXERGVlkQXERGVlkQXERGVlkQXERGVll8Yj5gkO82/\nfrXOXzpvvzUUSURvyYwuIiIqLYkuIiIqbdSlS0kzgLuAH1EUIp0GfMr2De1eSNIcYKHtRZIOsH3h\nKvRxOPDnwDPAS4C/t33NOM89GvgQ8Ce2f9Zw/OXAd4CXAVeXdeEaz3sn8A/l092AG8vHR9u+dRzX\nPQ3YFZht+zfjiTUiItac8ezR2fZsAEm7A8dSlK9pi+15ZR8zgEOAthJded5fAjvZflbS1sBZwLgS\nHfBu4M8ak1zD8atsf0HSTZTFTxvivpqiCgGSHq2PRRveA+yQJBcR0Rnt3oyyGfAQgKQFwAW2L5W0\nP3AgRZI4D3gKOA04GbgceATYGrgAOAyYKek44FRgAbARsB7wSdu3t7j2hhQzyvUpCpz+DJhVxnId\ncITtuyUdAWwKXAccBbwc+A9gB+Crkv7Mthv6/S3wEknvAh5sZzAkLQW2s/2UpC8Ad5cv7UtRnuea\n8s9LJO1v+8lR+hoE5gL09/czMDDQTiiV06pScK/LuDSXcRkpY7LSeBKdykQyDXgNY8/mtge2sP1Y\nuWx3he0ry8QIcBJFUjq+THY32z5R0o4UiXFWs05t3ynpVuDnki6nSKDfsf3cKLH8PvAm289I2qO8\nroe1eQKYA5wNfFTSNNv/O8Z7HMsWwK62a5I+Cuxr+6nRTiiXTAcBhoaW1Xq5HEtf3/SUo2kh4zJS\nPi8j9eqYtEru47kZxbZn294ZeCfwLUmjJcj7bD/W8Hy0fawdKWZe2L4NeOMYgXyIIhH+GDgauFrS\nlFFOudP2M61elPQW4HTg28DNwO8oKoOvrsW2a2ugn4iIWE1tLV3aXiLpaeB1FDen1K3X8Hj5sNOG\nP29UAxoT1dRWDcuEtoHte4B7JP0zsIRi9jTeWIb7KHA8cG35X42VN5uMx6peNyIiJklbv14gaRNg\nc4p9ut+UjwHe3kY3K1iZYBcDe5R978zKPa5mPgac2TCD25Ai/keGxbJbG7E8Bby2vFFkPnAu8C9t\nnP8bYHNJU4Gd2zgvIiImSTt7dFDs0x1he7mkfwW+IekAiqXE8boH2EHSycBxwDmSrqVIWoePct45\nwDbALZKeYuXNK09LOhP4sqSfAfe1EcuXgPMkHUQxm5wPfFfS6bbPHsf5pwGXAAZ+0sZ1owctPnL3\nTocQ0ZOm1GrZSuo2Q0PLevqH0qsb6WPJuDSXcRmpV8ekr29603s2uu67LiWdDmzb5KV9bT892fFE\nRMTaresSne3+TscQERHVke+6jIiISkuii4iISkuii4iISkuii4iISkuii4iISkuii4iISuu6Xy+I\nWBvtNP/6Cb/G0nn7Tfg1IqooM7qIiKi0js7oyqrhdwE/oqgEMA34lO0b2uxnDrDQ9iJJB9huq3p5\n2ccbgFOAV1F87+WNwNHld2luAbzK9q2NBWfbvUZEREy+bpjR1evd7QEcAxy7Ch3MK5PcDOCQds+X\ntA5wIXCK7Z1s7wAsBc4sm+wJzGy334iI6Lxu26PbDHiocdYkaX/gQIrq2+dRlNY5jaIa+eUUZXq2\nBi4ADgNmlpXLTwUWABuxstLB7S2u+y7gXts/aDj2RcCSNiuv/ayk+8vX9pB0BEUtvA/avkPS4cCh\nFGWILrI9X9IgsBXwemC27edXY2wiImIVdEOiq5cBmga8BtiHonp4M9sDW9h+TNJpwBW2rywTI8BJ\nFGWEji+T3c22T5S0I0VinNWi322AOxoP2K5Jupui6vkC4FHbF0t6P1Cz/W5Jfw18WNKvKZJxvS7f\njZLOLx+vb/sd4xiEQWAuQH9/PwMDA2OdUml9fdM7HUJXyrg0l3EZKWOyUjckOtueDSBpG+B84M4W\nbe+z/VjD81tH6XdH4LPlBW6T9MZR2tZoXt18CtBsFlbfQ3yIouDqTIpZ5X+Ux6cDM8YR4wtsD1LM\nHBkaWlbrxRIbdb1aYmQ8Mi4j5fMyUq+OSavk3g2J7gW2l0h6mmJmV7dew+Plw04Z/rxRjSJR1TVL\nZHVLKJY9X1BWMv894F7g3cPaP9fweEoZx2W2/3pYH3uOEWNEREywbrgZ5QWSNgE2p0g8m5eH3976\njBFWsDJ5Lwb2KPvdGbh7lPOuBl4v6T0Nx/4v8EPbjw/rt5kfUezbvVTSFEmnSnpJG3FHRMQE6YYZ\nXX2PDop9uiMolgS/IekA4Mdt9HUPsIOkk4HjgHMkXUuR0A9vdZLtFZL2Ac6QdHzZ/jbgk2WTRcDX\nJQ21OP9+SacA11MsdV5U/lpCG6FHRMREmFKr1TodQwwzNLSsp38ovbq/MJaMS3MZl5F6dUz6+qZP\naXa8G2Z0k0bS6cC2TV7a1/bTkx1PRERMvJ5KdLb7Ox1DRERMrq66GSUiImJNS6KLiIhKS6KLiIhK\nS6KLiIhKS6KLiIhKS6KLiIhKS6KLiIhK66nfo4tYm82Yc1nb5yw+cvcJiCRi7ZIZXUREVNqkz+gk\nzQDuovjG/xrFFzl/yvYNo53XpJ85wELbiyQdYPvCVYznEOBcYHPbj65KHw19PWp709XpIyIi1qxO\nLV02FlvdHTiWorJ4Ox3MK8+fARwCrFKiAw4F7qOoEH7GKvYRERFdqhv26DYDHpK0ALjA9qWS9qdI\nPIPAecBTwGnAycDlwCMUFb0voCiYOlPSccCpwAJgI4qCrZ+0fXurC5f172YCfwEcTZnoJH2IolzQ\ncuBO24dL2hs4oTz2BPCnFHXqvgm8jqL+Xb3fEW1tpwBrREQHdCrR1WvQTaOoJr4PRaJpZntgC9uP\nSToNuML2lWViBDgJOML28WWyu9n2iZJ2pEiMs0aJ4yDgUuBK4KuSXmP7IeAoYD/bD0j6aFlEdWPg\nUNs/l3RuGfPzwHq2d5H0NuATZb/N2l4yxoAMAnMB+vv7GRgYGK155fX1Te90CJXQK+PYK++zHRmT\nlbph6XIb4HzgzhZt77P9WMPzW0fpd0fgs+UFbpP0xjHiOBQ4wfbzki4ADga+CPwb8F1J5wH/VhZR\nHQLOkrQusBVwLbApcFN5vVsk1Uv9NGs7KtuDFDNYhoaW1XqxllRdr9bSmgi9MI75vIzUq2PSKrl3\n/K5L20uApylmdnXrNTwevuQ32hJgDWgsvDe1VUNJrwXeBsyX9GPg3cAHypj+CXg/xfhcK+mVwNco\nZo6zgO+V3UyhWL6sq49ns7YREdEBHU905T7Z5sCS8k+At7fRxQpWzkwXA3uU/e4M3D3KeYcAX7b9\nFtt/CAjYRNIbJH0WeNj2F4FFwJbAhsD9kjYqr7E+YIpZJJJ2BTYo+27WNiIiOqDTe3RQ7NMdATwE\nfEPSAcCP2+jrHmAHSScDxwHnSLqWIokfPsp5hwAfqj+xXZP0dYpZ3TJgkaQngf8u4/kycCNwL/B5\nimXG3YG/kLSQYun1obK7EW0lXWL74TbeV0RErAFTarVap2OIYYaGlvX0D6VX9xfGknFpLuMyUq+O\nSV/f9CnNjnfDrxdMKEmnA9s2eWlf2083OR4RERVS+URnu7/TMUREROd0/GaUiIiIiZREFxERlZZE\nFxERlZZEFxERlZZEFxERlZZEFxERlZZEFxERlVb536OLWNvtNP96AJbO26/DkUSsnTKji4iISluj\nMzpJM4C7gB9RlMyZBnzK9g1t9jMHWGh7kaQDbF+4CrFsDZwC9FGU67kJOMr2M+321dDnvwMfLft8\nle3RauNFREQXmIgZnW3Ptr0HcAxw7Cp0MK9McjMoqgy0RdJU4ELg87ZnUpbSoahusMpsf6D8fsw9\ngZmr01dEREyOid6j2wx4SNIC4ALbl0raHziQoszNecBTwGnAycDlwCPA1sAFwGHATEnHAacCC4CN\nKAqzftL27S2u+05gie2F8EIJnqMpi6RK+iJFopoGnGH7rDLG5cArgUsoauL1UdSpO8n22ZKWAu8o\nY39W0v3A74ATynOfAP4UeAnwbYr6dBsAh48Sa0RETKCJSHT1WnPTKKqG7wMc3aLt9sAWth+TdBpw\nhe0ry6QDcBJFpe7jy2R3s+0TJe1IkRhnteh3G4bVtKtXKpA0DVhq++8kvQS4DzirbPa47b+S9BHg\n94FdKZLuvwNnl22eoEi4j9q+WNJBwKG2fy7p3PL9rgc8aPtjkrYC3jTGmCFpEJgL0N/fz8DAwFin\nVFpf3/ROh9CVMi7NZVxGypisNBGJzrZnA0jaBjifoihpM/fZfqzh+Wh7XjsCny0vcJukN47Stkax\nL9csuP+VtImkmyhmYX0trr/I9vOSHqSoGN7KEHCWpHWBrYBrge8Dn5F0BvAd21eOcn49rkGKmSJD\nQ8tqvVhLqq5Xa2mNR8ZlpHxeRurVMWmV3Cf0rkvbS4CnKWZ2des1PF4+7JThzxvVgMaiek0TWWkJ\nw/bQJG0gaTtJsyj22GaVCbnx5pTG6z/X8LhpMb/S1yhmnbOA7wGUlcTfAnwHOKycjUZERAdMaKKT\ntAmwOUXi2bw8/PY2uljBylnnYmCPst+dgbtHOe9qYEtJ7y3brwOcCBwMbAo8YPtZSX8ETJW0fhsx\nDY9rQ+B+SRuV8a0vaW9gb9tXAZ9g5c0wERExySZyjw6KfbojgIeAb0g6gGF7Z2O4B9hB0skUd0ye\nI+laigR9eKuTbK+QtA9wpqS5FDO1q4FPA9OBYyQtBC4CLgW+0kZMAIuAr0saAr4M3AjcC3yeYvnx\nUOAkScdQJMW5bfYfERFryJRardbpGGKYoaFlPf1D6dX9hbFkXJrLuIzUq2PS1ze96TbTWv0VYJJO\nB7Zt8tK+9bssIyKit63Vic52f6djiIiI7pbvuoyIiEpLoouIiEpLoouIiEpLoouIiEpLoouIiEpL\noouIiEpbq3+9IKKXzJhz2aRcZ/GRu0/KdSImS2Z0ERFRaUl0ERFRaau8dClpBnAX8COKEjrTgE/Z\nvqHNfuYAC20vknSA7QtXIZatgVMoastNBW4CjrL9TIv2CygqmD8HvN72V8rCr7sCs23/pt0Yyn6/\nZ/uPV+XciIiYGKu7R9dYZHV34FiKCtvtdDCvPH8GcAjQVqKTNLU85xO2F0qaAnyJotrBP4xx7caC\nqO8BdljVJFf2lyQXEdFl1uTNKJsBD9VnS7YvlbQ/cCBF6ZrzgKeA04CTgcuBR4CtKWZXhwEzyyKl\npwILgI0oCrV+0vbtLa77TmCJ7YUAtmuSjqYoj4OkL1IUYZ0GnGH7rPqJkj4CbAf8Cng1cEkZ8z8A\nu1GMz2m2/7UsPVSvgfcoRR06AW8A/tb2FZIetb1pWY/uBIryQE8Af2p7tKKySBqkLOfT39/PwMDA\naM0rr1Wl4Jh4a+PYr40xT7SMyUqrm+jqteemUVQR3wc4ukXb7YEtbD9WLhNeYfvKMjECnERRqfv4\nMtndbPtESTtSJMZZLfrdhmE17uqVCyRNA5ba/jtJLwHuA84a3oHtkyQdDuwL7ABsZ3s3SS8D/lPS\nRWXTu22fUSal19l+j6R3A38DXNHQ5cbAobZ/LuncclwuaRF/PYZBiv8hYGhoWa0XS2zU9WqJkW6x\nto19Pi8j9eqYtEruq3szim3Ptr0zxczqW7ROnvfZfqzh+a2j9LsjcF15gduAN47StkaxL9csuP8F\nNpF0E0Ui6huln8Zr12eHvwV+SjHrHB5zfS/yQYrZXaMh4KyyuOsewCvHcd2IiJgAa+yuS9tLgKcp\nZnZ16zU8Hr50N9pSXg1oLKDXNJGVllAsTb5A0gaStpM0C9gTmFXuJTa9OWWMa69PuQw6LObnGh4P\nL/b3NYrZ6Szge+O4ZkRETJA1lugkbQJsTpF4Ni8Pv72NLlawcja4mGImhKSdWbk31szVwJaS3lu2\nXwc4ETgY2BR4wPazkv4ImCpp/THiWAzMLvt6OcUe3M/aeB9QzPDul7RR+T7GumZEREyQNbVHB8U+\n3RHAQ8A3JB3AsL2zMdwD7CDpZIo7Js+RdC1FMj681Um2V0jaBzhT0lyKWdfVwKeB6cAx5RLiRcCl\nwFdGC8L2DZJ+JOl6ihnpHNu/ldTGW+HLwI3AvcDngUFJl9h+uJ1OIhotnbdfT+67RKyuKbVardMx\nxDBDQ8t6+ofSqxvpY8m4NBldnbQAAANZSURBVJdxGalXx6Svb/rwbSRgLfquS0mnA9s2eWnf+l2W\nERERw601ic52f6djiIiItU++6zIiIiote3TRdSQNlr9AHw0yLs1lXEbKmLxYZnTRjeZ2OoAulXFp\nLuMyUsakQRJdRERUWhJdRERUWhJddKNPdzqALpVxaS7jMlLGpEFuRomIiErLjC4iIiotiS4iIiot\niS4iIiotiS4iIiotiS4iIiptrflS56guSesBC4AtgeeBj9r+72FtnqWo8Ve3l+3nJy3ISVTWZNyZ\notr9gO3FDa/tDXyOYpwut31CZ6KcfGOMy1LgAYpxAfig7YcmO8ZOkLQd8D3gZNunDXutZz8vjZLo\nohscCvza9gclvQv4J4oK8Y2etD170iObZJJmAVvb3kXSm4GvAbs0NPkSsA9FgeOFki60/dMOhDqp\nxjEuUJTsemryo+scSS8D/hn4QYsmPfl5GS5Ll9EN9gK+Wz6+Btitg7F02l7ARQC27wE2lvQKAElb\nAY/bfsD2CuDysn0vaDkuPe4Z4D3AL4a/0OOflxdJootu8CpgCKD8C1mTtP6wNtMkfVPSjZL+btIj\nnDwvjEVpqDzW7LVHgM0nKa5OG21c6s6QdIOkeZKaVpquGtvPjVJ4upc/Ly+SpcuYVJI+Dnx82OG3\nDXve7B+po4DzKPZnrpd0ve3bJiDEbjPaP9g98Y95C8Pf+3HAlcDjFDO/A4ALJjuoLtezn5ckuphU\nts8Czmo8JmkBxf993lnemDLF9vJh553R0P4HwO8DVUx0v+DFM5VXAw+3eO01NFmyqqjRxgXb59Yf\nS7qc4vPR64mulz8vL5Kly+gGVwEHlY/fC/xH44sqfFPSFEnrUuzh/WSSY5wsVwEHAkjaAfiF7WUA\ntpcCr5A0oxyH/cv2vaDluEjaUNL3G5a7ZwF3dybM7tHjn5cXyZc6R8dJmkoxy9uaYnP9I7YfkDQH\nWGh7kaQTgT2BFcDFtj/buYgnlqR5wO4U7/VwYHuKu06/K2l34MSy6YW2v9ChMCfdGOMyAHwYeBq4\nA/iE7cr/4ybprcB8YAbwLMXdlRcDP+/1z0ujJLqIiKi0LF1GRESlJdFFRESlJdFFRESlJdFFRESl\nJdFFRESlJdFFRESlJdFFRESlJdFFRESl/X/hWRCtU/4czQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaUfZ52NQtuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64b6ca6f-4d0b-4198-d15b-7d887d8ce894"
      },
      "source": [
        "# Produce the score of the test data prediction\n",
        "print(f'The Test Accuracy is: {round(mdl.score(test_X_scaled, test_y), 4)}')"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Test Accuracy is: 0.6757\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
