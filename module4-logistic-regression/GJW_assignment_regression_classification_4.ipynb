{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GJW_assignment_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iesous-kurios/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/GJW_assignment_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZxprF-ZsT-i",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHnKFVmQsT-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6adzAw6sT-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFqY0-KmsT-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m6YJ0z8sT-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F9Ti3FYsT-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXmdMh0tsT_D",
        "colab_type": "code",
        "outputId": "adddc41a-f5db-4822-ce95-cd47c8e14d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# Do train/validate/test split. \n",
        "# Train on reviews from 2016 & earlier. \n",
        "# Validate on 2017. \n",
        "# Test on 2018 & later.\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Other</td>\n",
              "      <td>1/28/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>California</td>\n",
              "      <td>1/30/2016</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.19</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/30/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California</td>\n",
              "      <td>2/1/2016</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>x</td>\n",
              "      <td>9.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Asada</td>\n",
              "      <td>2/6/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California  1/18/2016   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California  1/24/2016   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California  1/27/2016   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "5       Other  1/28/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "6  California  1/30/2016   3.0     2.9   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "7    Carnitas  1/30/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "8  California   2/1/2016   3.0     3.7     x  ...    NaN      NaN   NaN       NaN  False\n",
              "9       Asada   2/6/2016   4.0     4.1   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "\n",
              "[10 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPKE8WlK0OGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoM1il6A0Qa9",
        "colab_type": "code",
        "outputId": "7ec4faf9-a0b5-4494-85fa-80a5d541fb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "df.Great.isnull().value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    421\n",
              "Name: Great, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "772E94wp5Un7",
        "colab_type": "code",
        "outputId": "fe9227c9-534e-40f7-c6bf-a23a15cb3c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 421 entries, 0 to 422\n",
            "Data columns (total 59 columns):\n",
            "Burrito           421 non-null object\n",
            "Date              421 non-null datetime64[ns]\n",
            "Yelp              87 non-null float64\n",
            "Google            87 non-null float64\n",
            "Chips             26 non-null object\n",
            "Cost              414 non-null float64\n",
            "Hunger            418 non-null float64\n",
            "Mass (g)          22 non-null float64\n",
            "Density (g/mL)    22 non-null float64\n",
            "Length            283 non-null float64\n",
            "Circum            281 non-null float64\n",
            "Volume            281 non-null float64\n",
            "Tortilla          421 non-null float64\n",
            "Temp              401 non-null float64\n",
            "Meat              407 non-null float64\n",
            "Fillings          418 non-null float64\n",
            "Meat:filling      412 non-null float64\n",
            "Uniformity        419 non-null float64\n",
            "Salsa             396 non-null float64\n",
            "Synergy           419 non-null float64\n",
            "Wrap              418 non-null float64\n",
            "Unreliable        33 non-null object\n",
            "NonSD             7 non-null object\n",
            "Beef              179 non-null object\n",
            "Pico              158 non-null object\n",
            "Guac              154 non-null object\n",
            "Cheese            159 non-null object\n",
            "Fries             127 non-null object\n",
            "Sour cream        92 non-null object\n",
            "Pork              51 non-null object\n",
            "Chicken           21 non-null object\n",
            "Shrimp            21 non-null object\n",
            "Fish              6 non-null object\n",
            "Rice              36 non-null object\n",
            "Beans             35 non-null object\n",
            "Lettuce           11 non-null object\n",
            "Tomato            7 non-null object\n",
            "Bell peper        7 non-null object\n",
            "Carrots           1 non-null object\n",
            "Cabbage           8 non-null object\n",
            "Sauce             38 non-null object\n",
            "Salsa.1           7 non-null object\n",
            "Cilantro          15 non-null object\n",
            "Onion             17 non-null object\n",
            "Taquito           4 non-null object\n",
            "Pineapple         7 non-null object\n",
            "Ham               2 non-null object\n",
            "Chile relleno     4 non-null object\n",
            "Nopales           4 non-null object\n",
            "Lobster           1 non-null object\n",
            "Queso             0 non-null float64\n",
            "Egg               5 non-null object\n",
            "Mushroom          3 non-null object\n",
            "Bacon             3 non-null object\n",
            "Sushi             2 non-null object\n",
            "Avocado           13 non-null object\n",
            "Corn              3 non-null object\n",
            "Zucchini          1 non-null object\n",
            "Great             421 non-null bool\n",
            "dtypes: bool(1), datetime64[ns](1), float64(19), object(38)\n",
            "memory usage: 194.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TePT8nFZ2xSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Great = df.Great.astype(int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HFckALQ2_95",
        "colab_type": "code",
        "outputId": "af0db2ef-94a0-40b4-c22c-9261c5586e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "df.Great.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    239\n",
              "1    182\n",
              "Name: Great, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHqJ4g45vATA",
        "colab_type": "code",
        "outputId": "cae7da03-c976-46ab-b1cd-efcdeb81f96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "cutoff_train = pd.to_datetime('2017-01-01')\n",
        "cutoff_val = pd.to_datetime('2018-01-01')\n",
        "train = df[df.Date < cutoff_train]\n",
        "val = df[(df.Date < cutoff_val) & (df.Date >= cutoff_train)]\n",
        "test  = df[df.Date >= cutoff_val]\n",
        "print(train.shape, validate.shape, test.shape)\n",
        "sns.distplot(df['Great'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298, 59) (85, 59) (38, 59)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f64dba24e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNGwGOVD7lGh",
        "colab_type": "code",
        "outputId": "f3819fe4-a131-478a-8de0-0674b5f649f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# determine majority class\n",
        "target = 'Great'\n",
        "y_train = train[target]\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.590604\n",
              "1    0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBUUrnne7zWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# guess majority class for each prediction\n",
        "# TODO\n",
        "\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4gahVyQ8Awz",
        "colab_type": "code",
        "outputId": "d03fd540-d489-4633-a39e-a0a33773b1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# baseline accuracy if we guess majority class every prediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5906040268456376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGRwDpUW8NYs",
        "colab_type": "code",
        "outputId": "08a205f3-2a36-4637-f376-4a2ffc3dfcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# baseline accuracy using validate data\n",
        "y_val = val[target]\n",
        "y_pred = [majority_class] * len(y_val)\n",
        "accuracy_score(y_val, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5529411764705883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjxjQXwC8hpG",
        "colab_type": "code",
        "outputId": "4f60f5fc-e306-4b71-b9ae-696588651398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>298.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>298.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>6.896781</td>\n",
              "      <td>3.445286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.770920</td>\n",
              "      <td>3.472315</td>\n",
              "      <td>3.706360</td>\n",
              "      <td>3.551215</td>\n",
              "      <td>3.519024</td>\n",
              "      <td>3.528870</td>\n",
              "      <td>3.395946</td>\n",
              "      <td>3.324640</td>\n",
              "      <td>3.540203</td>\n",
              "      <td>3.955068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.409396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.371738</td>\n",
              "      <td>1.211412</td>\n",
              "      <td>0.852150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.081275</td>\n",
              "      <td>1.685043</td>\n",
              "      <td>0.137833</td>\n",
              "      <td>0.797606</td>\n",
              "      <td>0.991897</td>\n",
              "      <td>0.869483</td>\n",
              "      <td>0.850348</td>\n",
              "      <td>1.040457</td>\n",
              "      <td>1.089044</td>\n",
              "      <td>0.971226</td>\n",
              "      <td>0.922426</td>\n",
              "      <td>1.167341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.492550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>11.950000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp     Google        Cost  ...        Wrap  Queso       Great\n",
              "count  71.000000  71.000000  292.000000  ...  296.000000    0.0  298.000000\n",
              "mean    3.897183   4.142254    6.896781  ...    3.955068    NaN    0.409396\n",
              "std     0.478680   0.371738    1.211412  ...    1.167341    NaN    0.492550\n",
              "min     2.500000   2.900000    2.990000  ...    0.000000    NaN    0.000000\n",
              "25%     3.500000   4.000000    6.250000  ...    3.500000    NaN    0.000000\n",
              "50%     4.000000   4.200000    6.850000  ...    4.000000    NaN    0.000000\n",
              "75%     4.000000   4.400000    7.500000  ...    5.000000    NaN    1.000000\n",
              "max     4.500000   4.900000   11.950000  ...    5.000000    NaN    1.000000\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ17jMKj8lWT",
        "colab_type": "code",
        "outputId": "1201c36e-7a46-407b-cc7d-84c4a260cafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# 1. Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate this class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# 3. Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Uniformity', 'Meat:filling', 'Fillings', 'Temp', 'Cost', 'Hunger', 'Tortilla']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "# 4. Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train)\n",
        "\n",
        "# 5. Apply the model to new data.\n",
        "# The predictions look like this ...\n",
        "linear_reg.predict(X_val_imputed)\n",
        "\n",
        "## What do these numbers mean?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.31776263e-01,  4.70192603e-01,  4.24718563e-01,  4.53003746e-01,\n",
              "       -1.31374685e-03,  1.85533230e-01,  7.98069353e-01,  5.49946504e-01,\n",
              "       -2.61673535e-03,  6.47939633e-01,  6.14856224e-01,  3.86434724e-01,\n",
              "        3.18575022e-01,  2.95783145e-01,  9.11491725e-01,  3.27777689e-01,\n",
              "        3.77997164e-01,  5.00753009e-01,  5.83197468e-01,  9.45661839e-01,\n",
              "        6.94688148e-01,  4.12171554e-01,  1.28539472e-01,  5.09865839e-01,\n",
              "        6.75431159e-01,  5.66486133e-01,  7.04282828e-01,  4.48402984e-01,\n",
              "        4.99971450e-01,  5.12498176e-01,  7.25705900e-01,  4.05246024e-01,\n",
              "        2.63520168e-01,  3.72558884e-01,  2.74865814e-01,  4.09886675e-01,\n",
              "        5.61152102e-01,  5.56536943e-01,  6.17201486e-01,  5.85776667e-01,\n",
              "        3.05728984e-01,  4.70022939e-01,  5.06848918e-01,  8.21347552e-01,\n",
              "        4.74288607e-01,  4.51177750e-01,  9.20606529e-02,  3.69594445e-01,\n",
              "        7.75920911e-01, -1.20949128e-01,  4.14760929e-02,  4.16929440e-01,\n",
              "        6.82375995e-01,  6.66407832e-01,  3.34041702e-01,  2.20755936e-01,\n",
              "        1.28654693e-01,  3.59644291e-01,  3.05383969e-01,  2.59737222e-01,\n",
              "       -3.21415302e-01,  2.95347739e-01,  2.08650588e-01,  4.55528832e-01,\n",
              "        5.99407437e-01,  6.57550367e-01,  6.43678476e-01,  1.14581387e+00,\n",
              "        3.11911252e-01,  7.63402841e-01,  1.43592536e+00,  7.57544736e-01,\n",
              "        5.21783435e-01,  7.65497951e-01, -1.78537517e-01,  4.27406558e-01,\n",
              "        9.83236887e-02,  7.55190250e-01,  5.72987574e-01,  8.77597205e-01,\n",
              "        5.47456525e-01,  6.34389753e-01,  3.63900782e-01,  5.22439902e-01,\n",
              "        1.08649065e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8CPNoSX9c6R",
        "colab_type": "code",
        "outputId": "766882ea-a0d8-49e7-b188-9e7c7634cb62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# Get coefficients\n",
        "pd.Series(linear_reg.coef_, features)\n",
        "\n",
        "## What do these numbers mean?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Uniformity      0.031936\n",
              "Meat:filling    0.114000\n",
              "Fillings        0.229506\n",
              "Temp            0.066741\n",
              "Cost            0.044815\n",
              "Hunger          0.012886\n",
              "Tortilla        0.074176\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdxsXaIU-skH",
        "colab_type": "code",
        "outputId": "acc222ce-01e3-464f-b139-eeb44e518b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_case = [[19, 22, 3]]  # 19 inch long, circumference of 22, and 3 uniformity\n",
        "linear_reg.predict(test_case)\n",
        "\n",
        "## What does this number mean?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3425034])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iGZ4uze_FJv",
        "colab_type": "code",
        "outputId": "9c3e99fb-32c0-4654-be1d-3e2bca75c109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_imputed, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy3dOnVi_RnF",
        "colab_type": "code",
        "outputId": "55f52173-8cfc-4f04-d287-745c49128c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The logistic sigmoid \"squishing\" function, \n",
        "# implemented to accept numpy arrays\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e**(-x))\n",
        "\n",
        "# 1 + np.e**(-2) \n",
        "1 + np.e**(-322222) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XczKk0_q_VyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8YBfK-n_b8l",
        "colab_type": "code",
        "outputId": "f5aa1254-8de3-4988-a26f-0ecdb7971262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# TODO\n",
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.3.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.21.3)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoefQI03_kP6",
        "colab_type": "code",
        "outputId": "26285d22-0a78-42df-d85d-e7c86fdf3ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Burrito', 'Date', 'Yelp', 'Google', 'Chips', 'Cost', 'Hunger',\n",
              "       'Mass (g)', 'Density (g/mL)', 'Length', 'Circum', 'Volume', 'Tortilla',\n",
              "       'Temp', 'Meat', 'Fillings', 'Meat:filling', 'Uniformity', 'Salsa',\n",
              "       'Synergy', 'Wrap', 'Unreliable', 'NonSD', 'Beef', 'Pico', 'Guac',\n",
              "       'Cheese', 'Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp', 'Fish',\n",
              "       'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots',\n",
              "       'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', 'Onion', 'Taquito',\n",
              "       'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso',\n",
              "       'Egg', 'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini',\n",
              "       'Great'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOSl9hDR_e13",
        "colab_type": "code",
        "outputId": "2e9b7e3b-a766-4296-cd88-97757a3628a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# TODO\n",
        "import category_encoders as ce \n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "target = 'Great'\n",
        "features = ['Uniformity', 'Meat:filling', 'Fillings', 'Temp', 'Cost', 'Hunger', 'Tortilla']\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "# X_train_encoded.head()\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print ('Validation Accuracy', model.score(X_val_scaled,y_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO7Gd5Sm_7My",
        "colab_type": "code",
        "outputId": "a7154c41-e584-4541-e703-f6d0e6678742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "# TODO\n",
        "%matplotlib inline\n",
        "coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)\n",
        "coefficients.sort_values().plot.barh();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD4CAYAAADYU1DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeIfoDjsA54Y",
        "colab_type": "code",
        "outputId": "ab36d825-d8e3-4ea1-a1a0-9ed528c920b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# 1. Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate this class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# 3. Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Uniformity', 'Meat:filling', 'Fillings', 'Temp', 'Cost', 'Hunger', 'Tortilla']\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# 4. Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train)\n",
        "\n",
        "# 5. Apply the model to new data.\n",
        "# The predictions look like this ...\n",
        "linear_reg.predict(X_test_imputed)\n",
        "\n",
        "## What do these numbers mean?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.13038321,  1.05281151, -0.0377752 ,  1.19254201,  0.20989199,\n",
              "        0.35067225,  0.63404821,  0.87371447,  0.34666669,  0.70893637,\n",
              "        0.85630737,  0.44051877,  0.79818604,  0.4817522 ,  0.64832128,\n",
              "        0.66341317,  0.6517868 ,  0.18499184, -0.12397102,  0.2842136 ,\n",
              "        0.09992699,  0.70052689,  0.67870456,  0.70870418,  0.5573803 ,\n",
              "        0.24493686,  0.39012432,  1.10971831,  0.77341822,  0.57534716,\n",
              "        0.33552482,  0.45965911,  0.57598965,  0.54361357,  0.57046962,\n",
              "        0.44401933,  0.91107128,  0.67840945])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnRjSq9HDYLG",
        "colab_type": "code",
        "outputId": "b2470fe5-5c39-44a5-befb-3fb7544dd73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Test Accuracy', log_reg.score(X_test_imputed, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}